{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d_XrB849SNBz",
   "metadata": {
    "id": "d_XrB849SNBz",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Parameters\n",
    "\n",
    "# @markdown <h3>Main Parameters</h3>\n",
    "DATASET_NAME = \"MPQA-I\" #@param [\"MPQA-T\", \"MPQA-P\", \"MPQA-I\", \"AGNEWS\", \"AMZN-EN\"]\n",
    "AFL_APPROACH = \"FINE-TUNING\" #@param [\"FINE-TUNING\", \"IN-CONTEXT\"]\n",
    "BASE_MODEL = \"FLAN-T5\" #@param [\"BART\", \"FLAN-T5\", \"Uncharted\"]\n",
    "# @markdown &emsp; ↳ Model name and learning rate will be automatically configured if anything other than uncharted is selected. If uncharted is selected, the model name and learning rate need to be configured manually.\n",
    "AFL_METHOD = \"Rep(En)-ClUn(En)\" #@param [\"Random\", \"Rep(En)\", \"Rep(En)-Un\", \"Rep(En)-Rep(Sc)\", \"Rep(En)-Rep(En)\", \"Rep(En)-UnRep\", \"Rep(En)-ClUn(Sc)\", \"Rep(En)-ClUn(En)\", \"Uncharted\"]\n",
    "# @markdown &emsp; ↳ Embedding and sampling methods will be automatically configured if anything other than uncharted is selected. If uncharted is selected, the embedding and sampling methods need to be configured manually.\n",
    "SAMPLING_ITERATIONS = 10 #@param {type:'slider', min:1, max:32, step:1}\n",
    "NUMBER_OF_SAMPLES_PER_ITERATION = 10 #@param {type:'slider', min:3, max:100, step:1}\n",
    "# @markdown &emsp; ↳ M in paper; K = SAMPLING_ITERATIONS * M\n",
    "\n",
    "# @markdown <br/> <h3> Other Parameters </h3>\n",
    "RUNTIME_TYPE = 'COLAB' #@param [\"COLAB\", \"CONDA\"]\n",
    "EXPERIMENT_NAME = 'test'\n",
    "MAX_NEW_TOKENS = 5 #@param {type:'slider', min:1, max:20, step:1}\n",
    "LEARNING_RATE = 1e-4 #@param {\"type\": \"number\"}\n",
    "FP16 = False\n",
    "LOCAL_RANK = -1\n",
    "FP16_OPT_LEVEL = 'O1'\n",
    "FP16_FULL_EVAL = False\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 10 #@param {type: \"integer\"}\n",
    "PER_DEVICE_VAL_BATCH_SIZE = 64 #@param {type: \"integer\"}\n",
    "PER_DEVICE_VAL_BATCH_SIZE_EMBEDDING = 64 #@param {type: \"integer\"}\n",
    "LOGGING_STRATEGY = 'epoch'\n",
    "EVAL_STRATEGY = 'epoch'\n",
    "SAVE_STRATEGY = 'epoch'\n",
    "LOAD_BEST_MODEL_AT_END = True\n",
    "METRIC_FOR_BEST_MODEL = 'eval_main_metric'\n",
    "NUM_TRAIN_EPOCHS = 1000\n",
    "EARLY_STOPPING = 20 # Set 0 to disable\n",
    "SEED = 0\n",
    "MODEL_NAME = \"facebook/bart-base\" # @param [\"facebook/bart-base\",\"t5-small\",\"t5-base\",\"t5-large\",\"google/flan-t5-small\",\"google/flan-t5-base\",\"google/flan-t5-large\"] {\"allow-input\":true}\n",
    "EMBEDDING_METHOD_FIRST_ITERATION = \"FLAN-T5-ENCODER\" #@param [\"BART-ENCODER\", \"BART-SCORES\", \"BART-SCORES+ENCODER\", \"T5-ENCODER\", \"FLAN-T5-ENCODER\", \"FLAN-T5-SCORES\", \"FLAN-T5-SCORE+ENCODER\"]\n",
    "EMBEDDING_METHOD_SECOND_ITERATION_PLUS = \"SAME_AS_BEFORE\" #@param [\"SAME_AS_BEFORE\", \"SCORES\", \"SCORES+FLAN-T5\", \"BART\", \"T5\", \"FLAN-T5\"]\n",
    "EMBEDDING_PREFIX = None\n",
    "SAMPLING_METHOD_FIRST_ITERATION = \"KMEANS_REPRESENTATIVE\" #@param [\"BALANCED\", \"RANDOM\", \"KMEANS_RANDOM\", \"KMEANS_REPRESENTATIVE\"]\n",
    "SAMPLING_METHOD_SECOND_ITERATION_PLUS = \"SAME_AS_BEFORE\" #@param [\"SAME_AS_BEFORE\", \"ENTROPY_THEN_KMEANS_REPRESENTATIVE\", \"KMEANS_REPRESENTATIVE_THEN_ENTROPY\", \"ENTROPY\", \"BALANCED\", \"RANDOM\", \"KMEANS_RANDOM\", \"KMEANS_REPRESENTATIVE\"]\n",
    "REPEAT_SAMPLING = 5 #@param {type:'slider', min:1, max:10, step:1}\n",
    "# @markdown &emsp; ↳ Repeat the experiment with different sampling seeds ∊ [0, REPEAT_SAMPLING)\n",
    "KMEANS_INIT = 'random' #@param [\"k-means++\", \"random\"]\n",
    "KMEANS_CENTROID_SEEDS = 10 #@param {type:'slider', min:1, max:10, step:1}\n",
    "KMEANS_ALGORITHM = 'lloyd' #@param [\"lloyd\", \"elkan\"]\n",
    "UNREP_ALPHA = 10\n",
    "RESET_MODEL_AFTER_EACH_ITERATION = True #@param {type:\"boolean\"}\n",
    "PREDICT_WITH_GENERATE = True #@param {type:\"boolean\"}\n",
    "STORE_RESULTS = [] # Array of metrics' names: save and store results of a suite of notebooks\n",
    "# ↳ Example: ['eval_main_metric', 'eval_agnews_macro_f1']\n",
    "SHOW_VAL_PREDICTIONS = True #@param {type:\"boolean\"}\n",
    "MAX_FOLDS = 1\n",
    "\n",
    "# Checkpoints\n",
    "SKIP_SAMPLING_SEEDS = 0 # Skip the first few seeds if things went wrong during the previous runtime.\n",
    "RESTORE_CHECKPOINT_FROM_FILE = True #@param {type:\"boolean\"}\n",
    "# If restore from file was false, use the following checkpoint variables:\n",
    "INIT_FOLDS_VAL_LOG = [[]]\n",
    "INIT_FOLDS_TEST_LOG = [[]]\n",
    "INIT_PREDS_TEXTS_VAL_LIST = [[]]\n",
    "INIT_TARGETS_TEXTS_VAL_LIST = [ ]\n",
    "INIT_SAMPLED_LIST = [[]]\n",
    "\n",
    "# IDs\n",
    "TYPE_IDS = ['agreement', 'argue', 'intention', 'sentiment']\n",
    "POLARITY_IDS = ['negative', 'positive']\n",
    "INTENSITY_IDS = ['slight', 'low', 'medium', 'high', 'extreme']\n",
    "AGNEWS_IDS = ['world', 'sports', 'business', 'science']\n",
    "AMZN_IDS = ['1', '2', '3', '4', '5']\n",
    "\n",
    "# @markdown <br/> <h3> Dataset Links </h3>\n",
    "# @markdown *(Either URLs or local file paths)* <br/>\n",
    "\n",
    "# @markdown **MPQA Type**\n",
    "mpqa_t_train_link = '' #@param {type: \"string\"}\n",
    "mpqa_t_val_link   = '' #@param {type: \"string\"}\n",
    "mpqa_t_test_link  = '' #@param {type: \"string\"}\n",
    "\n",
    "# @markdown **MPQA Polarity**\n",
    "mpqa_p_train_link = '' #@param {type: \"string\"}\n",
    "mpqa_p_val_link   = '' #@param {type: \"string\"}\n",
    "mpqa_p_test_link  = '' #@param {type: \"string\"}\n",
    "\n",
    "# @markdown **MPQA Intensity**\n",
    "mpqa_i_train_link = '' #@param {type: \"string\"}\n",
    "mpqa_i_val_link   = '' #@param {type: \"string\"}\n",
    "mpqa_i_test_link  = '' #@param {type: \"string\"}\n",
    "\n",
    "# @markdown **AG News**\n",
    "agnews_trainval_link = '' #@param {type: \"string\"}\n",
    "agnews_test_link     = '' #@param {type: \"string\"}\n",
    "\n",
    "# @markdown **Amazon Reviews**\n",
    "amzn_train_link = '' #@param {type: \"string\"}\n",
    "amzn_val_link   = '' #@param {type: \"string\"}\n",
    "amzn_test_link  = '' #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XWcThH1lCtNx",
   "metadata": {
    "id": "XWcThH1lCtNx"
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_SAMPLES_PER_ITERATION = [NUMBER_OF_SAMPLES_PER_ITERATION] * SAMPLING_ITERATIONS if type(NUMBER_OF_SAMPLES_PER_ITERATION).__name__ != 'list' else NUMBER_OF_SAMPLES_PER_ITERATION # Can be a list too; the length of the list should be equal to the number of iterations\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = min(PER_DEVICE_TRAIN_BATCH_SIZE, min(NUMBER_OF_SAMPLES_PER_ITERATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8doff7pY3ekf",
   "metadata": {
    "id": "8doff7pY3ekf"
   },
   "outputs": [],
   "source": [
    "# Set the parameters that can be derived from the main parameters\n",
    "\n",
    "if BASE_MODEL == 'BART':\n",
    "    MODEL_NAME = 'facebook/bart-base'\n",
    "    LEARNING_RATE = 5e-5\n",
    "elif BASE_MODEL == 'FLAN-T5':\n",
    "    MODEL_NAME = 'google/flan-t5-base'\n",
    "    LEARNING_RATE = 1e-4\n",
    "\n",
    "if AFL_METHOD == 'Random':\n",
    "    SAMPLING_METHOD_FIRST_ITERATION = 'RANDOM'\n",
    "    NUMBER_OF_SAMPLES_PER_ITERATION *= SAMPLING_ITERATIONS\n",
    "    SAMPLING_ITERATIONS = 1\n",
    "\n",
    "elif AFL_METHOD == 'Rep(En)':\n",
    "    if BASE_MODEL == 'BART':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'BART-ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        NUMBER_OF_SAMPLES_PER_ITERATION *= SAMPLING_ITERATIONS\n",
    "        SAMPLING_ITERATIONS = 1\n",
    "    elif BASE_MODEL == 'FLAN-T5':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'FLAN-T5-ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        NUMBER_OF_SAMPLES_PER_ITERATION *= SAMPLING_ITERATIONS\n",
    "        SAMPLING_ITERATIONS = 1\n",
    "\n",
    "elif AFL_METHOD == 'Rep(En)-Un':\n",
    "    if BASE_MODEL == 'BART':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'BART-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'BART-SCORES'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'ENTROPY'\n",
    "    elif BASE_MODEL == 'FLAN-T5':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'FLAN-T5-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'FLAN-T5-SCORES'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'ENTROPY'\n",
    "\n",
    "elif AFL_METHOD == 'Rep(En)-Rep(Sc)':\n",
    "    if BASE_MODEL == 'BART':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'BART-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'BART-SCORES'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE'\n",
    "    elif BASE_MODEL == 'FLAN-T5':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'FLAN-T5-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'FLAN-T5-SCORES'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE'\n",
    "\n",
    "elif AFL_METHOD == 'Rep(En)-Rep(En)':\n",
    "    if BASE_MODEL == 'BART':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'BART-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'BART-ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE'\n",
    "    elif BASE_MODEL == 'FLAN-T5':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'FLAN-T5-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'FLAN-T5-ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE'\n",
    "\n",
    "elif AFL_METHOD == 'Rep(En)-UnRep':\n",
    "    if BASE_MODEL == 'BART':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'BART-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'BART-SCORES+ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'ENTROPY_THEN_KMEANS_REPRESENTATIVE'\n",
    "    elif BASE_MODEL == 'FLAN-T5':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'FLAN-T5-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'FLAN-T5-SCORES+ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'ENTROPY_THEN_KMEANS_REPRESENTATIVE'\n",
    "\n",
    "elif AFL_METHOD == 'Rep(En)-ClUn(Sc)':\n",
    "    if BASE_MODEL == 'BART':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'BART-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'BART-SCORES'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE_THEN_ENTROPY'\n",
    "    elif BASE_MODEL == 'FLAN-T5':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'FLAN-T5-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'FLAN-T5-SCORES'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE_THEN_ENTROPY'\n",
    "\n",
    "elif AFL_METHOD == 'Rep(En)-ClUn(En)':\n",
    "    if BASE_MODEL == 'BART':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'BART-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'BART-SCORES+ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE_THEN_ENTROPY'\n",
    "    elif BASE_MODEL == 'FLAN-T5':\n",
    "        EMBEDDING_METHOD_FIRST_ITERATION = 'FLAN-T5-ENCODER'\n",
    "        EMBEDDING_METHOD_SECOND_ITERATION_PLUS = 'FLAN-T5-SCORES+ENCODER'\n",
    "        SAMPLING_METHOD_FIRST_ITERATION = 'KMEANS_REPRESENTATIVE'\n",
    "        SAMPLING_METHOD_SECOND_ITERATION_PLUS = 'KMEANS_REPRESENTATIVE_THEN_ENTROPY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KQgSEbjZoaPX",
   "metadata": {
    "id": "KQgSEbjZoaPX"
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "%mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_SF7ZRNPzG1m",
   "metadata": {
    "id": "_SF7ZRNPzG1m"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce192a0a-9703-4393-ab55-c24cdd1222cc",
   "metadata": {
    "id": "ce192a0a-9703-4393-ab55-c24cdd1222cc"
   },
   "outputs": [],
   "source": [
    "if RUNTIME_TYPE == 'COLAB':\n",
    "    %pip install transformers==4.25.1 datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xyDbVHftZ0it",
   "metadata": {
    "id": "xyDbVHftZ0it"
   },
   "outputs": [],
   "source": [
    "# To assure deterministic results\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f96831-ae2c-4adc-8730-cc07b9b5ba74",
   "metadata": {
    "id": "96f96831-ae2c-4adc-8730-cc07b9b5ba74"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, EarlyStoppingCallback, AutoConfig\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, pairwise_distances_argmin_min, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from scipy.special import softmax\n",
    "from urllib.request import urlopen\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from functools import wraps\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WHtALgYKZzhP",
   "metadata": {
    "id": "WHtALgYKZzhP"
   },
   "outputs": [],
   "source": [
    "# Start timer\n",
    "\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lv87oZj_IXcE",
   "metadata": {
    "id": "Lv87oZj_IXcE"
   },
   "outputs": [],
   "source": [
    "# Support for third-party widgets\n",
    "\n",
    "if RUNTIME_TYPE == 'COLAB':\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ab8c6-603d-40af-875b-5b6f68f9accc",
   "metadata": {
    "id": "2d2ab8c6-603d-40af-875b-5b6f68f9accc"
   },
   "outputs": [],
   "source": [
    "# Setup device\n",
    "\n",
    "device_string = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_hf = 0 if torch.cuda.is_available() else -1\n",
    "device = torch.device(device_string)\n",
    "print(\"Device:\", device)\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a085e-a728-4a8e-8f75-193820216f52",
   "metadata": {
    "id": "856a085e-a728-4a8e-8f75-193820216f52"
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "CALLBACKS = []\n",
    "if EARLY_STOPPING > 0:\n",
    "    CALLBACKS.append(EarlyStoppingCallback(EARLY_STOPPING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a21171-f03f-45d1-9293-4bcb4183eb02",
   "metadata": {
    "id": "b6a21171-f03f-45d1-9293-4bcb4183eb02"
   },
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8vCH651D1kmE",
   "metadata": {
    "id": "8vCH651D1kmE"
   },
   "source": [
    "# Restore Last Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8nMi6Jju1i9T",
   "metadata": {
    "id": "8nMi6Jju1i9T"
   },
   "outputs": [],
   "source": [
    "if RESTORE_CHECKPOINT_FROM_FILE:\n",
    "    try:\n",
    "        with open(f'results/{EXPERIMENT_NAME.replace(\".ipynb\", \"\")}_checkpoint.json') as checkpoint_file:\n",
    "            checkpoint = json.load(checkpoint_file)\n",
    "            INIT_FOLDS_VAL_LOG = checkpoint['INIT_FOLDS_VAL_LOG']\n",
    "            INIT_FOLDS_TEST_LOG = checkpoint['INIT_FOLDS_TEST_LOG']\n",
    "            INIT_PREDS_TEXTS_VAL_LIST = checkpoint['INIT_PREDS_TEXTS_VAL_LIST']\n",
    "            INIT_SAMPLED_LIST = checkpoint['INIT_SAMPLED_LIST']\n",
    "            SKIP_SAMPLING_SEEDS = len(INIT_FOLDS_VAL_LOG[-1])\n",
    "            print(f\"Skipped the first {SKIP_SAMPLING_SEEDS} seeds.\")\n",
    "    except Exception as e:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65615ad0-5c82-4079-be75-122e75d8441c",
   "metadata": {
    "id": "65615ad0-5c82-4079-be75-122e75d8441c"
   },
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JgkEqLVciHXV",
   "metadata": {
    "id": "JgkEqLVciHXV"
   },
   "outputs": [],
   "source": [
    "# Classes\n",
    "\n",
    "TYPE_CLASSES = ['agreement', 'arguing', 'intention', 'sentiment']\n",
    "POLARITY_CLASSES = ['negative', 'positive']\n",
    "INTENSITY_CLASSES = ['low', 'low medium', 'medium', 'medium high', 'high']\n",
    "AGNEWS_CLASSES = [1, 2, 3, 4]\n",
    "AMZN_CLASSES = [1, 2, 3, 4, 5]\n",
    "\n",
    "NUM_TYPE_CLASSES = len(TYPE_CLASSES)\n",
    "NUM_POLARITY_CLASSES = len(POLARITY_CLASSES)\n",
    "NUM_INTENSITY_CLASSES = 5\n",
    "NUM_INTENSITY_UNITS = 3\n",
    "NUM_AGNEWS_CLASSES = len(AGNEWS_CLASSES)\n",
    "NUM_AMZN_CLASSES = len(AMZN_CLASSES)\n",
    "\n",
    "if DATASET_NAME == 'MPQA-T':\n",
    "    CLASSES = TYPE_CLASSES\n",
    "    NUM_CLASSES = NUM_TYPE_CLASSES\n",
    "    CLASS_IDS = TYPE_IDS\n",
    "elif DATASET_NAME == 'MPQA-P':\n",
    "    CLASSES = POLARITY_CLASSES\n",
    "    NUM_CLASSES = NUM_POLARITY_CLASSES\n",
    "    CLASS_IDS = POLARITY_IDS\n",
    "elif DATASET_NAME == 'MPQA-I':\n",
    "    CLASSES = INTENSITY_CLASSES\n",
    "    NUM_CLASSES = NUM_INTENSITY_CLASSES\n",
    "    CLASS_IDS = INTENSITY_IDS\n",
    "elif DATASET_NAME == 'AGNEWS':\n",
    "    CLASSES = AGNEWS_CLASSES\n",
    "    NUM_CLASSES = NUM_AGNEWS_CLASSES\n",
    "    CLASS_IDS = AGNEWS_IDS\n",
    "elif DATASET_NAME.startswith('AMZN'):\n",
    "    CLASSES = AMZN_CLASSES\n",
    "    NUM_CLASSES = NUM_AMZN_CLASSES\n",
    "    CLASS_IDS = AMZN_IDS\n",
    "else:\n",
    "    CLASSES = []\n",
    "    NUM_CLASSES = 0\n",
    "    CLASS_IDS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o-yP-vC9iOfm",
   "metadata": {
    "id": "o-yP-vC9iOfm"
   },
   "outputs": [],
   "source": [
    "# Create a map for class ids and class names\n",
    "\n",
    "type_classname2classindex = {\n",
    "    'agreement': 0,\n",
    "    'arguing':   1,\n",
    "    'intention': 2,\n",
    "    'sentiment': 3,\n",
    "}\n",
    "type_classname2classid = {\n",
    "    'agreement': TYPE_IDS[0],\n",
    "    'arguing':   TYPE_IDS[1],\n",
    "    'intention': TYPE_IDS[2],\n",
    "    'sentiment': TYPE_IDS[3],\n",
    "}\n",
    "type_classid2classname = {v:k for k, v in type_classname2classid.items()}\n",
    "type_classid2classindex = {type_classname2classid[k]:v for k, v in type_classname2classindex.items()}\n",
    "\n",
    "###\n",
    "\n",
    "polarity_classname2classindex = {\n",
    "    'negative': 0,\n",
    "    'positive': 1,\n",
    "}\n",
    "polarity_classname2classid = {\n",
    "    'negative': POLARITY_IDS[0],\n",
    "    'positive': POLARITY_IDS[1],\n",
    "}\n",
    "polarity_classid2classname = {v:k for k, v in polarity_classname2classid.items()}\n",
    "polarity_classid2classindex = {polarity_classname2classid[k]:v for k, v in polarity_classname2classindex.items()}\n",
    "\n",
    "###\n",
    "\n",
    "intensity_classname2classindices = {\n",
    "    'low':        [0],\n",
    "    'low medium': [0, 1],\n",
    "    'medium':        [1],\n",
    "    'medium high':   [1, 2],\n",
    "    'high':             [2],\n",
    "}\n",
    "intensity_classname2classid = {\n",
    "    'low':         INTENSITY_IDS[0],\n",
    "    'low medium':  INTENSITY_IDS[1],\n",
    "    'medium':      INTENSITY_IDS[2],\n",
    "    'medium high': INTENSITY_IDS[3],\n",
    "    'high':        INTENSITY_IDS[4],\n",
    "}\n",
    "intensity_classid2classname = {v:k for k, v in intensity_classname2classid.items()}\n",
    "intensity_classid2classindices = {intensity_classname2classid[k]:v for k, v in intensity_classname2classindices.items()}\n",
    "\n",
    "###\n",
    "\n",
    "agnews_classname2classindex = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "}\n",
    "agnews_classname2classid = {\n",
    "    1: AGNEWS_IDS[0],\n",
    "    2: AGNEWS_IDS[1],\n",
    "    3: AGNEWS_IDS[2],\n",
    "    4: AGNEWS_IDS[3],\n",
    "}\n",
    "agnews_classid2classname = {v:k for k, v in agnews_classname2classid.items()}\n",
    "agnews_classid2classindex = {agnews_classname2classid[k]:v for k, v in agnews_classname2classindex.items()}\n",
    "\n",
    "###\n",
    "\n",
    "amzn_classname2classindex = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "}\n",
    "amzn_classname2classid = {\n",
    "    1: AMZN_IDS[0],\n",
    "    2: AMZN_IDS[1],\n",
    "    3: AMZN_IDS[2],\n",
    "    4: AMZN_IDS[3],\n",
    "    5: AMZN_IDS[4],\n",
    "}\n",
    "amzn_classid2classname = {v:k for k, v in amzn_classname2classid.items()}\n",
    "amzn_classid2classindex = {amzn_classname2classid[k]:v for k, v in amzn_classname2classindex.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oMj4Vtcst4Fv",
   "metadata": {
    "id": "oMj4Vtcst4Fv"
   },
   "outputs": [],
   "source": [
    "# Labels Distribution\n",
    "\n",
    "def count_labels(Y=None, Y_train=None, Y_val=None, Y_test=None):\n",
    "\n",
    "    if Y==None:\n",
    "\n",
    "        count_dict = {}\n",
    "        for y in Y_train:\n",
    "            count_dict[y] = count_dict.get(y, 0) + 1\n",
    "        print('Train Labels distribution:', count_dict)\n",
    "\n",
    "        count_dict = {}\n",
    "        for y in Y_val:\n",
    "            count_dict[y] = count_dict.get(y, 0) + 1\n",
    "        print('Validation Labels distribution:', count_dict)\n",
    "\n",
    "        count_dict = {}\n",
    "        for y in Y_test:\n",
    "            count_dict[y] = count_dict.get(y, 0) + 1\n",
    "        print('Test Labels distribution:', count_dict)\n",
    "\n",
    "        Y = Y_train + Y_val + Y_test\n",
    "\n",
    "    count_dict = {}\n",
    "    for y in Y:\n",
    "        count_dict[y] = count_dict.get(y, 0) + 1\n",
    "    print('Labels distribution:', count_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fVJr8C-6U-YA",
   "metadata": {
    "id": "fVJr8C-6U-YA"
   },
   "outputs": [],
   "source": [
    "# Decompose X and y\n",
    "\n",
    "def decompose_mpqa(dataset):\n",
    "    if AFL_APPROACH == \"FINE-TUNING\":\n",
    "        X = [i for i in dataset.input]\n",
    "    elif AFL_APPROACH == \"IN-CONTEXT\":\n",
    "        X = ['{ ' + f'{\" \".join(i.splitlines())}' + ' } :' for i in dataset.input]\n",
    "\n",
    "    if DATASET_NAME == 'MPQA-T':\n",
    "        y = [i.replace(TYPE_CLASSES[0], TYPE_IDS[0]) \\\n",
    "              .replace(TYPE_CLASSES[1], TYPE_IDS[1]) \\\n",
    "              .replace(TYPE_CLASSES[2], TYPE_IDS[2]) \\\n",
    "              .replace(TYPE_CLASSES[3], TYPE_IDS[3]) for i in dataset.output]\n",
    "    elif DATASET_NAME == 'MPQA-P':\n",
    "        y = [i.replace(POLARITY_CLASSES[0], POLARITY_IDS[0]) \\\n",
    "              .replace(POLARITY_CLASSES[1], POLARITY_IDS[1]) for i in dataset.output]\n",
    "    elif DATASET_NAME == 'MPQA-I':\n",
    "        # Add special characters to avoid conflicts\n",
    "        y = [('!'+i+'!').replace('!'+INTENSITY_CLASSES[0]+'!', INTENSITY_IDS[0]) \\\n",
    "                        .replace('!'+INTENSITY_CLASSES[1]+'!', INTENSITY_IDS[1]) \\\n",
    "                        .replace('!'+INTENSITY_CLASSES[2]+'!', INTENSITY_IDS[2]) \\\n",
    "                        .replace('!'+INTENSITY_CLASSES[3]+'!', INTENSITY_IDS[3]) \\\n",
    "                        .replace('!'+INTENSITY_CLASSES[4]+'!', INTENSITY_IDS[4]) for i in dataset.output]\n",
    "    return X, y\n",
    "\n",
    "def decompose_agnews(dataset):\n",
    "    if AFL_APPROACH == \"FINE-TUNING\":\n",
    "        X = [f'{title} | {desc}' for title, desc in zip(dataset.Title, dataset.Description)]\n",
    "    elif AFL_APPROACH == \"IN-CONTEXT\":\n",
    "        X = ['{ ' + f'{\" \".join(title.splitlines())} | {\" \".join(desc.splitlines())}' + ' } :' for title, desc in zip(dataset.Title, dataset.Description)]\n",
    "    y = [AGNEWS_IDS[i-1] for i in dataset['Class Index']]\n",
    "    return X, y\n",
    "\n",
    "def decompose_amzn(dataset, filter_lang='en'):\n",
    "    X = []\n",
    "    y = []\n",
    "    for title, body, lang, stars in zip(dataset.review_title, dataset.review_body, dataset.language, dataset.stars):\n",
    "        if lang == filter_lang:\n",
    "            if AFL_APPROACH == \"FINE-TUNING\":\n",
    "                X = X + [f'{title} | {body}'[:900]]\n",
    "            elif AFL_APPROACH == \"IN-CONTEXT\":\n",
    "                X = X + ['{ ' + f'{\" \".join(title.splitlines())} | {\" \".join(body.splitlines())}'[:900] + ' } :']\n",
    "            y = y + [AMZN_IDS[stars-1]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RA2RdjfcZ4Lq",
   "metadata": {
    "id": "RA2RdjfcZ4Lq"
   },
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def pd_read_csv(link):\n",
    "    if link.startswith(\"http://\") or link.startswith(\"https://\"):\n",
    "        # Handle URLs\n",
    "        t = 15\n",
    "        while True:\n",
    "            try:\n",
    "                return pd.read_csv(link)\n",
    "            except Exception as e:\n",
    "                print(f\"Unsuccessful attempt to download {link}. Waiting for {t}s.\")\n",
    "                time.sleep(t)\n",
    "                t *= random.random()+1\n",
    "                t = int(t)\n",
    "                continue\n",
    "    else:\n",
    "        # Handle local file paths\n",
    "        return pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28384faa-36ff-4caa-b598-4946d990c7ba",
   "metadata": {
    "id": "28384faa-36ff-4caa-b598-4946d990c7ba"
   },
   "outputs": [],
   "source": [
    "# Fetch the dataset\n",
    "\n",
    "def fetch_dataset(dataset_name=DATASET_NAME, fold=0, show_counter=False):\n",
    "\n",
    "    if dataset_name.startswith('MPQA-'):\n",
    "\n",
    "        if dataset_name == 'MPQA-T':\n",
    "            trainset = pd_read_csv(mpqa_t_train_link)\n",
    "            valset   = pd_read_csv(mpqa_t_val_link)\n",
    "            testset  = pd_read_csv(mpqa_t_test_link)\n",
    "        elif dataset_name == 'MPQA-P':\n",
    "            trainset = pd_read_csv(mpqa_p_train_link)\n",
    "            valset   = pd_read_csv(mpqa_p_val_link)\n",
    "            testset  = pd_read_csv(mpqa_p_test_link)\n",
    "        elif dataset_name == 'MPQA-I':\n",
    "            trainset = pd_read_csv(mpqa_i_train_link)\n",
    "            valset   = pd_read_csv(mpqa_i_val_link)\n",
    "            testset  = pd_read_csv(mpqa_i_test_link)\n",
    "\n",
    "        X_train, y_train = decompose_mpqa(trainset)\n",
    "        X_val,   y_val   = decompose_mpqa(valset)\n",
    "        X_test,  y_test  = decompose_mpqa(testset)\n",
    "\n",
    "        if show_counter == True:\n",
    "            count_labels(Y_train=y_train, Y_val=y_val, Y_test=y_test)\n",
    "\n",
    "    elif dataset_name == 'AGNEWS':\n",
    "\n",
    "        trainvalset = pd_read_csv(agnews_trainval_link)\n",
    "        testset     = pd_read_csv(agnews_test_link)\n",
    "\n",
    "        X_train_val, y_train_val = decompose_agnews(trainvalset)\n",
    "        X_test,      y_test      = decompose_agnews(testset)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1200, shuffle=True, stratify=y_train_val, random_state=SEED)\n",
    "\n",
    "        if show_counter == True:\n",
    "            count_labels(Y_train=y_train, Y_val=y_val, Y_test=y_test)\n",
    "\n",
    "    elif dataset_name.startswith('AMZN'):\n",
    "\n",
    "        filter_lang = dataset_name[-2:].lower()\n",
    "\n",
    "        trainset = pd_read_csv(amzn_train_link)\n",
    "        valset   = pd_read_csv(amzn_val_link)\n",
    "        testset  = pd_read_csv(amzn_test_link)\n",
    "\n",
    "        X_train, y_train = decompose_amzn(trainset, filter_lang)\n",
    "        X_val,   y_val   = decompose_amzn(valset,   filter_lang)\n",
    "        X_test,  y_test  = decompose_amzn(testset,  filter_lang)\n",
    "\n",
    "        _, X_val, _, y_val = train_test_split(X_val, y_val, test_size=1200, shuffle=True, stratify=y_val, random_state=SEED)\n",
    "\n",
    "        if show_counter == True:\n",
    "            count_labels(Y_train=y_train, Y_val=y_val, Y_test=y_test)\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee725191-73e1-47ee-a8d6-1465aa32b6f4",
   "metadata": {
    "id": "ee725191-73e1-47ee-a8d6-1465aa32b6f4"
   },
   "outputs": [],
   "source": [
    "# All samples\n",
    "\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = fetch_dataset()\n",
    "\n",
    "print(f'First three samples (out of {len(y_train)+len(y_val)+len(y_test)} = {len(y_train)} + {len(y_val)} + {len(y_test)}):')\n",
    "for i in range(0, 3):\n",
    "    print('┌X:', X_train[i])\n",
    "    print('└y:', y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab1607-bad3-4222-b15c-0ac3ec39acd5",
   "metadata": {
    "id": "37ab1607-bad3-4222-b15c-0ac3ec39acd5"
   },
   "source": [
    "# Preparing the model and torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732e3ad-d4f0-4ee5-8d6c-0bdc523539f8",
   "metadata": {
    "id": "b732e3ad-d4f0-4ee5-8d6c-0bdc523539f8"
   },
   "outputs": [],
   "source": [
    "# Load the hf model and tokenizer\n",
    "\n",
    "def load_tokenizer(model_name=MODEL_NAME):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "    return tokenizer\n",
    "\n",
    "def load_model(model_name=MODEL_NAME):\n",
    "    model_hf = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_name, resume_download=True,\n",
    "        config=AutoConfig.from_pretrained(model_name)\n",
    "    )\n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in model_hf.parameters() if p.requires_grad)\n",
    "    print('Number of trainable parameters in base model:', pytorch_total_params)\n",
    "\n",
    "    return model_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bga6t-ZBdJlN",
   "metadata": {
    "id": "Bga6t-ZBdJlN"
   },
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer()\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g9_I4PiZrNS2",
   "metadata": {
    "id": "g9_I4PiZrNS2"
   },
   "outputs": [],
   "source": [
    "# Show how each class is tokenized\n",
    "\n",
    "for class_id in CLASS_IDS:\n",
    "    print(f'{class_id}: {tokenizer(class_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1odOETprA-P",
   "metadata": {
    "id": "b1odOETprA-P"
   },
   "outputs": [],
   "source": [
    "# Store the first token only\n",
    "\n",
    "if MODEL_NAME in ['google/flan-t5-base']:\n",
    "    CLASSES_TOKENS = [tokenizer(class_id).input_ids[0] for class_id in CLASS_IDS]\n",
    "elif MODEL_NAME in ['facebook/bart-base']:\n",
    "    CLASSES_TOKENS = [tokenizer(class_id).input_ids[1] for class_id in CLASS_IDS]\n",
    "else:\n",
    "    raise Exception('The behavior for new tokenizer needs to be configured.')\n",
    "print(CLASSES_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psC9urXWVUGm",
   "metadata": {
    "id": "psC9urXWVUGm"
   },
   "outputs": [],
   "source": [
    "if EMBEDDING_METHOD_FIRST_ITERATION in ['BART-ENCODER']:\n",
    "    emb_tokenizer = load_tokenizer('facebook/bart-base')\n",
    "if EMBEDDING_METHOD_FIRST_ITERATION in ['T5-ENCODER']:\n",
    "    emb_tokenizer = load_tokenizer('t5-base')\n",
    "if EMBEDDING_METHOD_FIRST_ITERATION in ['FLAN-T5-ENCODER']:\n",
    "    emb_tokenizer = load_tokenizer('google/flan-t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gPKlVbH-rHkl",
   "metadata": {
    "id": "gPKlVbH-rHkl"
   },
   "outputs": [],
   "source": [
    "# Load optimizer\n",
    "\n",
    "def load_optimizer(model):\n",
    "    opt_parameters = model.parameters()\n",
    "    return torch.optim.AdamW(opt_parameters, lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ceb2ae-6206-4e83-92b7-46b7a22c93d0",
   "metadata": {
    "id": "33ceb2ae-6206-4e83-92b7-46b7a22c93d0"
   },
   "outputs": [],
   "source": [
    "# Tokenize the inputs\n",
    "\n",
    "@functools.cache\n",
    "def tokenize_inputs(tokenizer, X, y):\n",
    "    if type(X) is tuple:\n",
    "        X = list(X)\n",
    "        y = list(y)\n",
    "\n",
    "    Xy_tokenized = tokenizer(X, text_target=y, truncation=True)\n",
    "    return Xy_tokenized\n",
    "\n",
    "def tokenize_and_show_inputs(tokenizer, X='', y=''):\n",
    "    print(\"\\nPretokenized examples:\")\n",
    "    for i in range(1, min(len(y)+1, 4)):\n",
    "        print(f'┌X: \"{X[-i]}\"')\n",
    "        print(f'└y: \"{y[-i]}\"')\n",
    "    print()\n",
    "\n",
    "    if type(X) is list:\n",
    "        X = tuple(X)\n",
    "        y = tuple(y)\n",
    "\n",
    "    return tokenize_inputs(tokenizer, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Wx14kixomjf",
   "metadata": {
    "id": "8Wx14kixomjf"
   },
   "outputs": [],
   "source": [
    "def batch_detokenize(tokenizer, tokens):\n",
    "    tokens = np.where(tokens != -100, tokens, tokenizer.pad_token_id) # Replace -100 in the labels as we can't decode them\n",
    "    texts = tokenizer.batch_decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        text = texts[i].strip()\n",
    "        texts[i] = text\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZWryAdwqkzut",
   "metadata": {
    "id": "ZWryAdwqkzut"
   },
   "outputs": [],
   "source": [
    "print(tokenize_and_show_inputs(tokenizer, [\"\"], [\"\"]))\n",
    "print()\n",
    "print(tokenize_and_show_inputs(tokenizer, [\"Holding out for a hero\"], [\"hero\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb9aae-3aa3-47a4-befe-cf9a80978ebd",
   "metadata": {
    "id": "d1fb9aae-3aa3-47a4-befe-cf9a80978ebd"
   },
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx]) # torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "def get_dataset(Xy_tokenized):\n",
    "    dataset = Dataset(Xy_tokenized)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b844adf-e40c-4712-b714-79ece6327c28",
   "metadata": {
    "id": "1b844adf-e40c-4712-b714-79ece6327c28"
   },
   "outputs": [],
   "source": [
    "# DataCollator\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nZulkQLFUh7r",
   "metadata": {
    "id": "nZulkQLFUh7r"
   },
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloader(dataset, batch_size):\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, collate_fn=data_collator\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qc3Ifox5E4_j",
   "metadata": {
    "id": "qc3Ifox5E4_j"
   },
   "source": [
    "# Metrics and Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0vTFTVIgKY5U",
   "metadata": {
    "id": "0vTFTVIgKY5U"
   },
   "outputs": [],
   "source": [
    "X_eval, y_eval = X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kxr8FJsmzEMR",
   "metadata": {
    "id": "kxr8FJsmzEMR"
   },
   "outputs": [],
   "source": [
    "def merge_samples(X, Y):\n",
    "    merged_samples = {}\n",
    "    for x, y in zip(X, Y):\n",
    "        if x not in merged_samples:\n",
    "            merged_samples[x] = set()\n",
    "        merged_samples[x].add(y)\n",
    "    merged_y = [list(merged_samples[x]) for x in X]\n",
    "    return merged_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q2jW6bOw61HO",
   "metadata": {
    "id": "Q2jW6bOw61HO"
   },
   "outputs": [],
   "source": [
    "# Remove duplicate samples after merging their outputs\n",
    "\n",
    "def squeeze_samples(X, candidates, referenceses):\n",
    "    squeezed_candidates_dict = {}\n",
    "    squeezed_referenceses_dict = {}\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        if x not in squeezed_candidates_dict:\n",
    "            squeezed_candidates_dict[x] = candidates[i]\n",
    "            squeezed_referenceses_dict[x] = referenceses[i]\n",
    "    squeezed_X = list(squeezed_candidates_dict.keys())\n",
    "    squeezed_candidates = list(squeezed_candidates_dict.values())\n",
    "    squeezed_referenceses_dict = list(squeezed_referenceses_dict.values())\n",
    "    return squeezed_X, squeezed_candidates, squeezed_referenceses_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NZRy5cpue9Pu",
   "metadata": {
    "id": "NZRy5cpue9Pu"
   },
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hWRoXjnE7Hp6",
   "metadata": {
    "id": "hWRoXjnE7Hp6"
   },
   "outputs": [],
   "source": [
    "# \" One | Two | Three \" => [\"One\", \"Two\", \"Three\"]\n",
    "def split_and_clean(text, separator=' '):\n",
    "    return [part_of_text.strip() for part_of_text in text.strip().split(separator)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trzOgwF0HgFa",
   "metadata": {
    "id": "trzOgwF0HgFa"
   },
   "outputs": [],
   "source": [
    "def apply_on_vec_mpqa(vec, t_id=None, p_id=None, i_id=None, t_ids=None, p_ids=None, i_ids=None):\n",
    "    t_index = None\n",
    "\n",
    "    if t_id:\n",
    "        t_ids = [t_id]\n",
    "    if t_ids:\n",
    "        for t_id in t_ids:\n",
    "            if t_id in type_classid2classname:\n",
    "                t_index = type_classid2classindex[t_id]\n",
    "                vec[t_index] = 1\n",
    "\n",
    "    if p_id:\n",
    "        p_ids = [p_id]\n",
    "    if p_ids:\n",
    "        p_startpos = 0\n",
    "        for p_id in p_ids:\n",
    "            if p_id in polarity_classid2classname:\n",
    "                p_index = polarity_classid2classindex[p_id]\n",
    "                vec[p_startpos + p_index] = 1\n",
    "\n",
    "    if i_id:\n",
    "        i_ids = [i_id]\n",
    "    if i_ids:\n",
    "        i_startpos = 0\n",
    "        for i_id in i_ids:\n",
    "            if i_id in intensity_classid2classname:\n",
    "                i_indices = intensity_classid2classindices[i_id]\n",
    "                for i_index in i_indices:\n",
    "                    vec[i_startpos + i_index] = 1\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cGwb4umpA2PW",
   "metadata": {
    "id": "cGwb4umpA2PW"
   },
   "outputs": [],
   "source": [
    "def apply_on_vec_agnews(vec, id=None, ids=None):\n",
    "    if id:\n",
    "        ids = [id]\n",
    "    if ids:\n",
    "        startpos = 0\n",
    "        for id in ids:\n",
    "            if id in agnews_classid2classname:\n",
    "                index = agnews_classid2classindex[id]\n",
    "                vec[startpos + index] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DhIovTmM6ypL",
   "metadata": {
    "id": "DhIovTmM6ypL"
   },
   "outputs": [],
   "source": [
    "def apply_on_vec_amzn(vec, id=None, ids=None):\n",
    "    if id:\n",
    "        ids = [id]\n",
    "    if ids:\n",
    "        startpos = 0\n",
    "        for id in ids:\n",
    "            if id in amzn_classid2classname:\n",
    "                index = amzn_classid2classindex[id]\n",
    "                vec[startpos + index] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9QvUtA4sNfLH",
   "metadata": {
    "id": "9QvUtA4sNfLH"
   },
   "outputs": [],
   "source": [
    "def outputs_text_to_vec(outputs_text):\n",
    "\n",
    "    if DATASET_NAME == 'MPQA-T':\n",
    "        outputs_vec = np.zeros((len(outputs_text), 4), dtype=int) # Empty 5-dimensional vector\n",
    "        for batch_i in range(len(outputs_text)):\n",
    "            t_ids = split_and_clean(outputs_text[batch_i], ' ')\n",
    "            outputs_vec[batch_i] = apply_on_vec_mpqa(outputs_vec[batch_i], t_ids=t_ids)\n",
    "\n",
    "    elif DATASET_NAME == 'MPQA-P':\n",
    "        outputs_vec = np.zeros((len(outputs_text), 2), dtype=int) # Empty 3-dimensional vector\n",
    "        for batch_i in range(len(outputs_text)):\n",
    "            p_ids = split_and_clean(outputs_text[batch_i], ' ')\n",
    "            outputs_vec[batch_i] = apply_on_vec_mpqa(outputs_vec[batch_i], p_id=p_ids[0])\n",
    "\n",
    "    elif DATASET_NAME == 'MPQA-I':\n",
    "        outputs_vec = np.zeros((len(outputs_text), 3), dtype=int) # Empty 3-dimensional vector\n",
    "        for batch_i in range(len(outputs_text)):\n",
    "            i_ids = split_and_clean(outputs_text[batch_i], ' ')\n",
    "            outputs_vec[batch_i] = apply_on_vec_mpqa(outputs_vec[batch_i], i_ids=i_ids)\n",
    "\n",
    "    elif DATASET_NAME == 'AGNEWS':\n",
    "        outputs_vec = np.zeros((len(outputs_text), 4), dtype=int) # Empty 4-dimensional vector\n",
    "        for batch_i in range(len(outputs_text)):\n",
    "            ids = split_and_clean(outputs_text[batch_i], ' ')\n",
    "            outputs_vec[batch_i] = apply_on_vec_agnews(outputs_vec[batch_i], id=ids[0])\n",
    "\n",
    "    elif DATASET_NAME.startswith('AMZN'):\n",
    "        outputs_vec = np.zeros((len(outputs_text), 5), dtype=int) # Empty 5-dimensional vector\n",
    "        for batch_i in range(len(outputs_text)):\n",
    "            ids = split_and_clean(outputs_text[batch_i], ' ')\n",
    "            outputs_vec[batch_i] = apply_on_vec_amzn(outputs_vec[batch_i], id=ids[0])\n",
    "\n",
    "    return outputs_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tVyDFTibdVBZ",
   "metadata": {
    "id": "tVyDFTibdVBZ"
   },
   "source": [
    "### MPQA Type Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RbYLl01JdkD7",
   "metadata": {
    "id": "RbYLl01JdkD7"
   },
   "outputs": [],
   "source": [
    "def calculate_type_metrics(preds, targets, decimals=6):\n",
    "    targets = targets[:, :NUM_TYPE_CLASSES]\n",
    "    preds   = preds[:, :NUM_TYPE_CLASSES]\n",
    "\n",
    "    accuracy_list = np.sum(preds == targets, axis=0).astype(float) / preds.shape[0]\n",
    "    f1_list = f1_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
    "    precision_list = precision_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
    "    recall_list = recall_score(y_true=targets, y_pred=preds, zero_division=0, average=None)\n",
    "\n",
    "    TP = np.sum(preds & targets)\n",
    "    FP = np.sum(preds & (1-targets))\n",
    "    FN = np.sum((1-preds) & targets)\n",
    "\n",
    "    if TP + FP > 0:\n",
    "        micro_precision = TP / (TP + FP)\n",
    "    else:\n",
    "        micro_precision = 1\n",
    "\n",
    "    if TP + FN > 0:\n",
    "        micro_recall = TP / (TP + FN)\n",
    "    else:\n",
    "        micro_recall = 1\n",
    "\n",
    "    micro_f1 = statistics.harmonic_mean([micro_precision, micro_recall])\n",
    "    micro_accuracy = np.mean(preds == targets)\n",
    "\n",
    "    # macro_precision = np.mean(precision_list)\n",
    "    # macro_recall = np.mean(recall_list)\n",
    "    # macro_f1 = statistics.harmonic_mean([macro_precision, macro_recall])\n",
    "    # macro_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # hamming_loss = np.mean(preds != targets) # The fraction of labels that are incorrectly predicted\n",
    "    exact_match_ratio = np.mean(np.sum(preds == targets, axis = 1) == NUM_TYPE_CLASSES) # The percentage of samples that have all their labels classified correctly\n",
    "\n",
    "    return {\n",
    "        'type_exact_match_ratio': np.round(exact_match_ratio, decimals),\n",
    "        'type_micro_f1': np.round(micro_f1, decimals),\n",
    "        'type_micro_precision': np.round(micro_precision, decimals),\n",
    "        'type_micro_recall': np.round(micro_recall, decimals),\n",
    "        'type_micro_accuracy': np.round(np.mean(micro_accuracy), decimals),\n",
    "        # 'type_hamming': np.round(hamming_loss, decimals),\n",
    "        # 'type_macro_f1': np.round(macro_f1, decimals),\n",
    "        # 'type_macro_precision': np.round(macro_precision, decimals),\n",
    "        # 'type_macro_recall': np.round(macro_recall, decimals),\n",
    "        # 'type_macro_accuracy': np.round(macro_accuracy, decimals),\n",
    "        'type_f1': np.round(f1_list, decimals).tolist(),\n",
    "        'type_precision': np.round(precision_list, decimals).tolist(),\n",
    "        'type_recall': np.round(recall_list, decimals).tolist(),\n",
    "        'type_accuracy': np.round(accuracy_list, decimals).tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pSgNzr7geHaa",
   "metadata": {
    "id": "pSgNzr7geHaa"
   },
   "source": [
    "### MPQA Polarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ebfftf57VPh0",
   "metadata": {
    "id": "Ebfftf57VPh0"
   },
   "outputs": [],
   "source": [
    "def calculate_polarity_f1_measure(extracted_polarity_preds, extracted_polarity_targets):\n",
    "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
    "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
    "    polarity_weighted_f1 = f1_score(extracted_polarity_targets, extracted_polarity_preds, average='weighted')\n",
    "    return polarity_weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7F1SuOxLaYRY",
   "metadata": {
    "id": "7F1SuOxLaYRY"
   },
   "outputs": [],
   "source": [
    "def calculate_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets):\n",
    "    extracted_polarity_targets = np.argmax(extracted_polarity_targets, axis=-1)\n",
    "    extracted_polarity_preds   = np.argmax(extracted_polarity_preds,   axis=-1)\n",
    "    polarity_score = np.sum(extracted_polarity_preds == extracted_polarity_targets)\n",
    "    return polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dzNgqFOraaXS",
   "metadata": {
    "id": "dzNgqFOraaXS"
   },
   "outputs": [],
   "source": [
    "def calculate_polarity_metrics(preds, targets, decimals=6):\n",
    "    batch_size = len(preds)\n",
    "\n",
    "    extracted_polarity_targets = targets\n",
    "    extracted_polarity_preds   = preds\n",
    "\n",
    "    number_of_samples = batch_size\n",
    "\n",
    "    polarity_acc = calculate_polarity_correctness_score(extracted_polarity_preds, extracted_polarity_targets) / number_of_samples\n",
    "    polarity_weighted_f1 = calculate_polarity_f1_measure(extracted_polarity_preds, extracted_polarity_targets)\n",
    "\n",
    "    return {\n",
    "        'polarity_accuracy': np.round(polarity_acc, decimals),\n",
    "        'polarity_weighted_f1': np.round(polarity_weighted_f1, decimals),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ejh-pD5ceUdB",
   "metadata": {
    "id": "Ejh-pD5ceUdB"
   },
   "source": [
    "### MPQA Intensity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PY58rZzsKuvN",
   "metadata": {
    "id": "PY58rZzsKuvN"
   },
   "outputs": [],
   "source": [
    "# Convert 3-dim intensity vector to its corresponding number\n",
    "\n",
    "def get_intensity_id(vec):\n",
    "    vec = vec.tolist()\n",
    "    if vec == [1, 0, 0]:\n",
    "        return 0\n",
    "    if vec == [1, 1, 0]:\n",
    "        return 1\n",
    "    if vec == [0, 1, 0]:\n",
    "        return 2\n",
    "    if vec == [0, 1, 1]:\n",
    "        return 3\n",
    "    if vec == [0, 0, 1]:\n",
    "        return 4\n",
    "    return 1 # everything is equal to low-medium by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KfWRGMa3IRto",
   "metadata": {
    "id": "KfWRGMa3IRto"
   },
   "outputs": [],
   "source": [
    "def calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=1):\n",
    "    batch_size = len(extracted_intensity_preds)\n",
    "    intensity_score = 0\n",
    "    for i in range(batch_size):\n",
    "        target_id = get_intensity_id(extracted_intensity_targets[i]) # everything is equal to low-medium by default\n",
    "        pred_id   = get_intensity_id(extracted_intensity_preds[i])   # everything is equal to low-medium by default\n",
    "        if abs(target_id - pred_id) <= d:\n",
    "            intensity_score += 1\n",
    "    return intensity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TmjDLJJjU-nJ",
   "metadata": {
    "id": "TmjDLJJjU-nJ"
   },
   "outputs": [],
   "source": [
    "def calculate_intensity_custom_weighted_f1_measure(extracted_intensity_preds, extracted_intensity_targets):\n",
    "\n",
    "    whole = 1.0\n",
    "    with_penalty = 0\n",
    "    half_false = 1\n",
    "    thresh = 0.5\n",
    "    trues = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0}  # TP\n",
    "    cnt = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0}    # TP + FN\n",
    "    falses = {'medium': 0, 'medium-high': 0, 'low': 0, 'high': 0, 'low-medium': 0} # FP\n",
    "\n",
    "    preds_indices = np.argmax(extracted_intensity_preds, axis=-1)\n",
    "\n",
    "    for i in range(len(preds_indices)):\n",
    "\n",
    "        if preds_indices[i] == 0:\n",
    "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
    "                falses['low'] += 1\n",
    "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
    "                falses['low'] += half_false\n",
    "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
    "                falses['low'] += half_false\n",
    "\n",
    "        if preds_indices[i] == 1:\n",
    "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
    "                falses['medium'] += half_false\n",
    "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
    "                falses['medium'] += half_false\n",
    "\n",
    "        if preds_indices[i] == 2:\n",
    "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
    "                falses['high'] += 1\n",
    "            if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
    "                falses['high'] += 1\n",
    "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
    "                falses['high'] += half_false\n",
    "            if extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
    "                falses['high'] += half_false\n",
    "\n",
    "        if extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 0:\n",
    "            cnt['low'] += 1\n",
    "            if preds_indices[i] == 0:\n",
    "                trues['low'] += whole\n",
    "\n",
    "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
    "            cnt['medium'] += 1\n",
    "            if preds_indices[i] == 1:\n",
    "                trues['medium'] += whole\n",
    "            else:\n",
    "                trues['medium'] += with_penalty\n",
    "\n",
    "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 0 and  extracted_intensity_targets[i][2] == 1:\n",
    "            cnt['high'] += 1\n",
    "            if preds_indices[i] == 2:\n",
    "                trues['high'] += whole\n",
    "\n",
    "        elif extracted_intensity_targets[i][0] == 1 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 0:\n",
    "            cnt['low-medium'] += 1\n",
    "            if preds_indices[i] == 0 or preds_indices[i] == 1:\n",
    "                trues['low-medium'] += whole\n",
    "\n",
    "        elif extracted_intensity_targets[i][0] == 0 and  extracted_intensity_targets[i][1] == 1 and  extracted_intensity_targets[i][2] == 1:\n",
    "            cnt['medium-high'] += 1\n",
    "            if preds_indices[i] == 1 or preds_indices[i] == 2:\n",
    "                trues['medium-high'] += whole\n",
    "\n",
    "    weighted_f1 = 0\n",
    "    weights = 0\n",
    "    for intensity_class in trues.keys():\n",
    "        try:\n",
    "            intensity_class_precision = trues[intensity_class] / (trues[intensity_class] + falses[intensity_class])\n",
    "        except:\n",
    "            intensity_class_precision = 1\n",
    "        try:\n",
    "            intensity_class_recall = trues[intensity_class] / cnt[intensity_class]\n",
    "        except:\n",
    "            intensity_class_recall = 1\n",
    "        intensity_class_f1 = statistics.harmonic_mean([intensity_class_precision, intensity_class_recall])\n",
    "        weighted_f1 += intensity_class_f1 * cnt[intensity_class]\n",
    "        weights += cnt[intensity_class]\n",
    "    custom_intensity_weighted_f1 = weighted_f1 / weights\n",
    "\n",
    "    return custom_intensity_weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bl-rW6LfacIX",
   "metadata": {
    "id": "bl-rW6LfacIX"
   },
   "outputs": [],
   "source": [
    "def calculate_intensity_custom_correctness_score(extracted_intensity_preds, extracted_intensity_targets):\n",
    "    extracted_intensity_preds_argmax = np.argmax(extracted_intensity_preds, axis=-1)\n",
    "    intensity_custom_score = 0\n",
    "    for i in range(len(extracted_intensity_preds_argmax)):\n",
    "        if (extracted_intensity_targets[i, extracted_intensity_preds_argmax[i]] == 1):\n",
    "            intensity_custom_score += 1\n",
    "    return intensity_custom_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pmzE32JJafGz",
   "metadata": {
    "id": "pmzE32JJafGz"
   },
   "outputs": [],
   "source": [
    "def calculate_intensity_metrics(preds, targets, decimals=6):\n",
    "    batch_size = len(preds)\n",
    "\n",
    "    extracted_intensity_targets = targets\n",
    "    extracted_intensity_preds = preds\n",
    "\n",
    "    number_of_samples = batch_size\n",
    "\n",
    "    intensity_acc    = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=0) / number_of_samples\n",
    "    intensity_d1_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=1) / number_of_samples\n",
    "    intensity_d2_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=2) / number_of_samples\n",
    "    intensity_d3_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=3) / number_of_samples\n",
    "    intensity_d4_acc = calculate_intensity_d_correctness_score(extracted_intensity_preds, extracted_intensity_targets, d=4) / number_of_samples\n",
    "    intensity_custom_acc = calculate_intensity_custom_correctness_score(extracted_intensity_preds, extracted_intensity_targets) / number_of_samples\n",
    "    intensity_custom_weighted_f1 = calculate_intensity_custom_weighted_f1_measure(extracted_intensity_preds, extracted_intensity_targets)\n",
    "\n",
    "    return {\n",
    "        'intensity_accuracy': np.round(intensity_acc, decimals),\n",
    "        'intensity_d1_accuracy': np.round(intensity_d1_acc, decimals),\n",
    "        'intensity_d2_accuracy': np.round(intensity_d2_acc, decimals),\n",
    "        'intensity_d3_accuracy': np.round(intensity_d3_acc, decimals),\n",
    "        'intensity_d4_accuracy': np.round(intensity_d4_acc, decimals),\n",
    "        'intensity_custom_accuracy': np.round(intensity_custom_acc, decimals),\n",
    "        'intensity_custom_weighted_f1': np.round(intensity_custom_weighted_f1, decimals),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eCbgcZVoCk1P",
   "metadata": {
    "id": "eCbgcZVoCk1P"
   },
   "source": [
    "### AG News Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jp7jqXAaCk1P",
   "metadata": {
    "id": "jp7jqXAaCk1P"
   },
   "outputs": [],
   "source": [
    "def calculate_agnews_f1_measure(extracted_preds, extracted_targets, average='weighted'):\n",
    "    extracted_targets = np.argmax(extracted_targets, axis=-1)\n",
    "    extracted_preds   = np.argmax(extracted_preds,   axis=-1)\n",
    "    weighted_f1 = f1_score(extracted_targets, extracted_preds, average=average)\n",
    "    return weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-9irBri8Ck1Q",
   "metadata": {
    "id": "-9irBri8Ck1Q"
   },
   "outputs": [],
   "source": [
    "def calculate_agnews_correctness_score(extracted_preds, extracted_targets):\n",
    "    extracted_targets = np.argmax(extracted_targets, axis=-1)\n",
    "    extracted_preds   = np.argmax(extracted_preds,   axis=-1)\n",
    "    score = np.sum(extracted_preds == extracted_targets)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HDidr9kuCk1Q",
   "metadata": {
    "id": "HDidr9kuCk1Q"
   },
   "outputs": [],
   "source": [
    "def calculate_agnews_metrics(preds, targets, decimals=6):\n",
    "    batch_size = len(preds)\n",
    "\n",
    "    extracted_targets = targets\n",
    "    extracted_preds   = preds\n",
    "\n",
    "    number_of_samples = batch_size\n",
    "\n",
    "    acc = calculate_agnews_correctness_score(extracted_preds, extracted_targets) / number_of_samples\n",
    "    weighted_f1 = calculate_agnews_f1_measure(extracted_preds, extracted_targets, average='weighted')\n",
    "    macro_f1 = calculate_agnews_f1_measure(extracted_preds, extracted_targets, average='macro')\n",
    "\n",
    "    return {\n",
    "        'agnews_accuracy': np.round(acc, decimals),\n",
    "        'agnews_weighted_f1': np.round(weighted_f1, decimals),\n",
    "        'agnews_macro_f1': np.round(macro_f1, decimals),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7HkhOZmF7o74",
   "metadata": {
    "id": "7HkhOZmF7o74"
   },
   "source": [
    "### Amazon Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BsLkA9iP7o74",
   "metadata": {
    "id": "BsLkA9iP7o74"
   },
   "outputs": [],
   "source": [
    "def calculate_amzn_f1_measure(extracted_preds, extracted_targets, average='weighted'):\n",
    "    extracted_targets = np.argmax(extracted_targets, axis=-1)\n",
    "    extracted_preds   = np.argmax(extracted_preds,   axis=-1)\n",
    "    weighted_f1 = f1_score(extracted_targets, extracted_preds, average=average)\n",
    "    return weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ZmdrU7A7o75",
   "metadata": {
    "id": "5ZmdrU7A7o75"
   },
   "outputs": [],
   "source": [
    "def calculate_amzn_correctness_score(extracted_preds, extracted_targets):\n",
    "    extracted_targets = np.argmax(extracted_targets, axis=-1)\n",
    "    extracted_preds   = np.argmax(extracted_preds,   axis=-1)\n",
    "    score = np.sum(extracted_preds == extracted_targets)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kQv7Tc5I7o75",
   "metadata": {
    "id": "kQv7Tc5I7o75"
   },
   "outputs": [],
   "source": [
    "def calculate_amzn_metrics(preds, targets, decimals=6):\n",
    "    batch_size = len(preds)\n",
    "\n",
    "    extracted_targets = targets\n",
    "    extracted_preds   = preds\n",
    "\n",
    "    number_of_samples = batch_size\n",
    "\n",
    "    acc = calculate_amzn_correctness_score(extracted_preds, extracted_targets) / number_of_samples\n",
    "    weighted_f1 = calculate_amzn_f1_measure(extracted_preds, extracted_targets, average='weighted')\n",
    "    macro_f1 = calculate_amzn_f1_measure(extracted_preds, extracted_targets, average='macro')\n",
    "\n",
    "    return {\n",
    "        'amzn_accuracy': np.round(acc, decimals),\n",
    "        'amzn_weighted_f1': np.round(weighted_f1, decimals),\n",
    "        'amzn_macro_f1': np.round(macro_f1, decimals),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LowrJ4U9dO6q",
   "metadata": {
    "id": "LowrJ4U9dO6q"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Romelqk1ajX-",
   "metadata": {
    "id": "Romelqk1ajX-"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(pred):\n",
    "    targets = np.array(pred.label_ids, dtype=int)\n",
    "    targets = batch_detokenize(tokenizer, targets)\n",
    "\n",
    "    preds   = pred.predictions\n",
    "    preds   = batch_detokenize(tokenizer, preds)\n",
    "\n",
    "    candidates = preds\n",
    "    # unmerged_referenceses = [[target] for target in targets]\n",
    "    referenceses = merge_samples(X_eval, targets)\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    if DATASET_NAME.startswith('MPQA'):\n",
    "        targets = outputs_text_to_vec(targets)\n",
    "        preds   = outputs_text_to_vec(preds)\n",
    "\n",
    "        if DATASET_NAME == 'MPQA-T':\n",
    "            metrics.update(calculate_type_metrics(preds, targets))\n",
    "            metrics['main_metric'] = metrics['type_micro_f1']\n",
    "\n",
    "        elif DATASET_NAME == 'MPQA-P':\n",
    "            metrics.update(calculate_polarity_metrics(preds, targets))\n",
    "            metrics['main_metric'] = metrics['polarity_accuracy']\n",
    "\n",
    "        elif DATASET_NAME == 'MPQA-I':\n",
    "            metrics.update(calculate_intensity_metrics(preds, targets))\n",
    "            metrics['main_metric'] = metrics['intensity_accuracy']\n",
    "\n",
    "    elif DATASET_NAME == 'AGNEWS':\n",
    "        targets = outputs_text_to_vec(targets)\n",
    "        preds   = outputs_text_to_vec(preds)\n",
    "        metrics.update(calculate_agnews_metrics(preds, targets))\n",
    "        metrics['main_metric'] = metrics['agnews_accuracy']\n",
    "\n",
    "    elif DATASET_NAME.startswith('AMZN'):\n",
    "        targets = outputs_text_to_vec(targets)\n",
    "        preds   = outputs_text_to_vec(preds)\n",
    "        metrics.update(calculate_amzn_metrics(preds, targets))\n",
    "        metrics['main_metric'] = metrics['amzn_accuracy']\n",
    "\n",
    "    if X_eval == X_val:\n",
    "        print('┌X:          ', X_eval[0])\n",
    "        print('├Candidate:  ', candidates[0])\n",
    "        print('└References: ', referenceses[0])\n",
    "        print('┌X:          ', X_eval[-1])\n",
    "        print('├Candidate:  ', candidates[-1])\n",
    "        print('└References: ', referenceses[-1])\n",
    "        print('--- Next Epoch ---')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfde22e-6ec5-409d-9d5f-bafb21d8d0e9",
   "metadata": {
    "id": "2dfde22e-6ec5-409d-9d5f-bafb21d8d0e9"
   },
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QdusgCNayB0B",
   "metadata": {
    "id": "QdusgCNayB0B"
   },
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "\n",
    "def get_training_args(fold_counter, seed_counter):\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir = f'models/{EXPERIMENT_NAME}_{fold_counter}_{seed_counter}',\n",
    "        overwrite_output_dir = True,\n",
    "        per_device_train_batch_size = PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size = PER_DEVICE_VAL_BATCH_SIZE,\n",
    "        local_rank = LOCAL_RANK,\n",
    "        fp16 = FP16,\n",
    "        fp16_opt_level = FP16_OPT_LEVEL,\n",
    "        fp16_full_eval = FP16_FULL_EVAL,\n",
    "        logging_strategy = LOGGING_STRATEGY,\n",
    "        evaluation_strategy = EVAL_STRATEGY,\n",
    "        save_strategy = SAVE_STRATEGY,\n",
    "        save_total_limit = 1,\n",
    "        num_train_epochs = NUM_TRAIN_EPOCHS,\n",
    "        load_best_model_at_end = LOAD_BEST_MODEL_AT_END,\n",
    "        metric_for_best_model = METRIC_FOR_BEST_MODEL,\n",
    "        dataloader_num_workers = NUM_WORKERS,\n",
    "        seed = SEED,\n",
    "        group_by_length = True,\n",
    "        predict_with_generate = PREDICT_WITH_GENERATE,\n",
    "        report_to = \"none\",\n",
    "        full_determinism = True\n",
    "    )\n",
    "    print(\"Number of GPUs:\", training_args.n_gpu)\n",
    "    print(\"Parallel Mode:\", training_args.parallel_mode)\n",
    "    print()\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mrgr2ccAX40c",
   "metadata": {
    "id": "Mrgr2ccAX40c"
   },
   "outputs": [],
   "source": [
    "def free_gpu():\n",
    "    try: # Delete the \"model\" after moving it to CPU, if it exists.\n",
    "        model\n",
    "    except NameError:\n",
    "        None\n",
    "    else:\n",
    "        model.cpu()\n",
    "        del model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705257c-d00c-4257-9f91-f1bfd918776a",
   "metadata": {
    "id": "7705257c-d00c-4257-9f91-f1bfd918776a"
   },
   "outputs": [],
   "source": [
    "# Setup trainer\n",
    "\n",
    "def setup_trainer(model, train_dataset, val_dataset, optimizer, fold_counter, seed_counter):\n",
    "    training_args = get_training_args(fold_counter, seed_counter)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        optimizers = (optimizer, None),\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = val_dataset,\n",
    "        data_collator = data_collator,\n",
    "        compute_metrics = calculate_metrics,\n",
    "        callbacks = CALLBACKS\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zgik1HRpGevG",
   "metadata": {
    "id": "Zgik1HRpGevG"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DaGnbrV1a-bE",
   "metadata": {
    "id": "DaGnbrV1a-bE"
   },
   "outputs": [],
   "source": [
    "def get_embedding_bart_encoder(X, y, model):\n",
    "    if model == None:\n",
    "        free_gpu()\n",
    "        model = load_model('facebook/bart-base')\n",
    "        model = model.to(device)\n",
    "\n",
    "    Xy_tokenized = tokenize_inputs(emb_tokenizer, tuple(X), tuple(y))\n",
    "    dataset = get_dataset(Xy_tokenized)\n",
    "    dataloader = get_dataloader(dataset, PER_DEVICE_VAL_BATCH_SIZE_EMBEDDING)\n",
    "\n",
    "    encoder = []\n",
    "    for batch in dataloader:\n",
    "        gpu_batch = {k:v.to(device) for k,v in batch.items() if k != 'labels'}\n",
    "        output = model(**gpu_batch)\n",
    "\n",
    "        # print(output.logits.size())                    # torch.Size([16, maxlen, 50265])\n",
    "        # print(output.encoder_last_hidden_state.size()) # torch.Size([16, maxlen, 768])\n",
    "\n",
    "        batch_encoder = torch.reshape(\n",
    "            torch.sum(output.encoder_last_hidden_state, 1) / torch.sum(torch.reshape(gpu_batch['attention_mask'], (len(batch['attention_mask']), -1, 1)).expand(output.encoder_last_hidden_state.size()), 1)\n",
    "        , (len(batch['attention_mask']), -1)).to('cpu').detach().numpy()\n",
    "\n",
    "        encoder.append(batch_encoder)\n",
    "\n",
    "        del gpu_batch\n",
    "\n",
    "    model.cpu()\n",
    "    del model\n",
    "    free_gpu()\n",
    "\n",
    "    encoder = np.concatenate(encoder, axis=0)\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BHifUulofn59",
   "metadata": {
    "id": "BHifUulofn59"
   },
   "outputs": [],
   "source": [
    "def get_embedding_bart_scores(X, y, model, get_encoder=False):\n",
    "    if model is None:\n",
    "        raise Exception(f\"`model` is not defined.\")\n",
    "\n",
    "    Xy_tokenized = tokenize_inputs(emb_tokenizer, tuple(X), tuple(y))\n",
    "    dataset = get_dataset(Xy_tokenized)\n",
    "    dataloader = get_dataloader(dataset, PER_DEVICE_VAL_BATCH_SIZE_EMBEDDING)\n",
    "\n",
    "    scores = [] # (len(X), NUM_CLASSES)\n",
    "    encoder = [] # List to store encoder's last hidden states\n",
    "\n",
    "    for batch in dataloader:\n",
    "        gpu_batch = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(**gpu_batch, output_hidden_states=get_encoder, return_dict=True)\n",
    "\n",
    "        if get_encoder:\n",
    "            encoder.append(\n",
    "                torch.reshape(\n",
    "                    torch.sum(outputs.encoder_hidden_states[-1], 1) /\n",
    "                    torch.sum(\n",
    "                        torch.reshape(\n",
    "                            gpu_batch[\"attention_mask\"],\n",
    "                            (len(batch[\"attention_mask\"]), -1, 1)\n",
    "                        ).expand(outputs.encoder_hidden_states[-1].size()),\n",
    "                        1\n",
    "                    ),\n",
    "                    (len(batch[\"attention_mask\"]), -1)\n",
    "                ).to(\"cpu\").detach().numpy()\n",
    "            )\n",
    "\n",
    "        logits = outputs.logits # (batch_size, seq_len, vocab_size)\n",
    "        logits = logits.cpu().detach().numpy()\n",
    "        sequences = np.argmax(logits, axis=-1) # (batch_size, seq_len)\n",
    "\n",
    "        batch_scores = np.zeros((logits.shape[0], logits.shape[1], NUM_CLASSES)) # (batch_size, seq_len, NUM_CLASSES)\n",
    "        for seq_tokens_i in range(1, logits.shape[1] - 1):\n",
    "            for class_token_i, class_token in enumerate(CLASSES_TOKENS):\n",
    "                batch_scores[:, seq_tokens_i, class_token_i] = logits[:, seq_tokens_i, class_token]\n",
    "            for batch_i in range(logits.shape[0]): # Softmax over class tokens for valid predictions\n",
    "                if sequences[batch_i, seq_tokens_i] in CLASSES_TOKENS:\n",
    "                    batch_scores[batch_i, seq_tokens_i] = softmax(batch_scores[batch_i, seq_tokens_i], axis=-1)\n",
    "                else:\n",
    "                    batch_scores[batch_i, seq_tokens_i] = 0\n",
    "        batch_scores = np.max(batch_scores, axis=1).reshape(-1, NUM_CLASSES) # Reduce seq_len dimension\n",
    "\n",
    "        scores.append(batch_scores)\n",
    "\n",
    "        del gpu_batch\n",
    "\n",
    "    # Convert scores and encoder hidden states to single arrays\n",
    "    scores = np.concatenate(scores, axis=0)\n",
    "    encoder = np.concatenate(encoder, axis=0) if get_encoder else None\n",
    "\n",
    "    if get_encoder:\n",
    "        return scores, encoder\n",
    "    else:\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RUPQwZIQjG0i",
   "metadata": {
    "id": "RUPQwZIQjG0i"
   },
   "outputs": [],
   "source": [
    "def get_embedding_t5_encoder(X, y, model=None, flan=False, prefix=None):\n",
    "    if model == None:\n",
    "        free_gpu()\n",
    "        embedding_model_name = 't5-base' if flan == False else 'google/flan-t5-base'\n",
    "        model = load_model(embedding_model_name)\n",
    "        model = model.to(device)\n",
    "\n",
    "    X_with_prefix = X\n",
    "    if prefix is not None:\n",
    "        X_with_prefix = [prefix+x for x in X]\n",
    "\n",
    "    Xy_tokenized = tokenize_inputs(emb_tokenizer, tuple(X_with_prefix), tuple(y))\n",
    "    dataset = get_dataset(Xy_tokenized)\n",
    "    dataloader = get_dataloader(dataset, PER_DEVICE_VAL_BATCH_SIZE_EMBEDDING)\n",
    "\n",
    "    encoder = []\n",
    "    for batch in dataloader:\n",
    "        gpu_batch = {k:v.to(device) for k,v in batch.items() if k != 'labels'}\n",
    "        output = model.encoder(**gpu_batch, return_dict=True)\n",
    "\n",
    "        # print(output.last_hidden_state.size()) # torch.Size([16, maxlen, 768])\n",
    "\n",
    "        batch_encoder = torch.reshape(\n",
    "            torch.sum(output.last_hidden_state, 1) / torch.sum(torch.reshape(gpu_batch['attention_mask'], (len(batch['attention_mask']), -1, 1)).expand(output.last_hidden_state.size()), 1)\n",
    "        , (len(batch['attention_mask']), -1)).to('cpu').detach().numpy()\n",
    "\n",
    "        encoder.append(batch_encoder)\n",
    "\n",
    "        del gpu_batch\n",
    "\n",
    "    model.cpu()\n",
    "    del model\n",
    "    free_gpu()\n",
    "\n",
    "    encoder = np.concatenate(encoder, axis=0)\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHa5H4BTMWDf",
   "metadata": {
    "id": "ZHa5H4BTMWDf"
   },
   "outputs": [],
   "source": [
    "def get_embedding_t5_scores(X, y, model, get_encoder=False):\n",
    "    if model is None:\n",
    "        raise Exception(f'`model` is not defined.')\n",
    "\n",
    "    Xy_tokenized = tokenize_inputs(tokenizer, tuple(X), tuple(y))\n",
    "    dataset = get_dataset(Xy_tokenized)\n",
    "    dataloader = get_dataloader(dataset, PER_DEVICE_VAL_BATCH_SIZE_EMBEDDING)\n",
    "\n",
    "    scores = []  # (len(X), NUM_CLASSES)\n",
    "    encoder = []  # List to store the encoder's last hidden states\n",
    "\n",
    "    for batch in dataloader:\n",
    "        gpu_batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "\n",
    "        output = model.generate(**gpu_batch, return_dict_in_generate=True, output_scores=True, max_new_tokens=MAX_NEW_TOKENS, renormalize_logits=True, output_hidden_states=get_encoder)\n",
    "\n",
    "        if get_encoder:\n",
    "            encoder.append(\n",
    "                torch.reshape(\n",
    "                    torch.sum(output.encoder_hidden_states[-1], 1) /\n",
    "                    torch.sum(\n",
    "                        torch.reshape(\n",
    "                            gpu_batch[\"attention_mask\"],\n",
    "                            (len(batch[\"attention_mask\"]), -1, 1)\n",
    "                        ).expand(output.encoder_hidden_states[-1].size()),\n",
    "                        1\n",
    "                    ),\n",
    "                    (len(batch[\"attention_mask\"]), -1)\n",
    "                ).to(\"cpu\").detach().numpy()\n",
    "            )\n",
    "\n",
    "        outputsequences = output.sequences.cpu().detach().numpy()\n",
    "        outputscores = np.array([score.cpu().detach().numpy() for score in output.scores])\n",
    "        outputscores = outputscores.transpose([1, 0, 2]) # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "        batch_scores = np.zeros((outputscores.shape[0], outputscores.shape[1], NUM_CLASSES)) # (batch_size, seq_len, NUM_CLASSES)\n",
    "        for seq_tokens_i in range(outputscores.shape[1]-1):\n",
    "            for class_token_i, class_token in enumerate(CLASSES_TOKENS):\n",
    "                batch_scores[:, seq_tokens_i, class_token_i] = outputscores[:, seq_tokens_i, class_token]\n",
    "            for batch_i in range(outputscores.shape[0]): # Ignore non class tokens, and softmax over class tokens\n",
    "                if outputsequences[batch_i, seq_tokens_i+1] in CLASSES_TOKENS:\n",
    "                    batch_scores[batch_i, seq_tokens_i] = softmax(batch_scores[batch_i, seq_tokens_i], axis=-1)\n",
    "                else:\n",
    "                    batch_scores[batch_i, seq_tokens_i] = 0\n",
    "        batch_scores = np.max(batch_scores, axis=1).reshape(-1, NUM_CLASSES) # (batch_size, NUM_CLASSES) # This is especially important for multi-label tasks\n",
    "\n",
    "        scores.append(batch_scores)\n",
    "\n",
    "        del gpu_batch\n",
    "\n",
    "    # Convert scores and encoder hidden states to single arrays\n",
    "    scores = np.concatenate(scores, axis=0)\n",
    "    encoder = np.concatenate(encoder, axis=0) if get_encoder else None\n",
    "\n",
    "    if get_encoder:\n",
    "        return scores, encoder\n",
    "    else:\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CZ79ZspjaBJm",
   "metadata": {
    "id": "CZ79ZspjaBJm"
   },
   "outputs": [],
   "source": [
    "def get_embedding(X, y, embedding_method=EMBEDDING_METHOD_FIRST_ITERATION, model=None):\n",
    "    with torch.no_grad():\n",
    "        if embedding_method == 'BART-ENCODER':\n",
    "            return get_embedding_bart_encoder(X, y, model)\n",
    "        elif embedding_method == 'BART-SCORES':\n",
    "            return get_embedding_bart_scores(X, y, model)\n",
    "        elif embedding_method == 'BART-SCORES+ENCODER':\n",
    "            return get_embedding_bart_scores(X, y, model, get_encoder=True)\n",
    "        elif embedding_method == 'T5-ENCODER':\n",
    "            return get_embedding_t5_encoder(X, y, model=model, flan=False, prefix=EMBEDDING_PREFIX)\n",
    "        elif embedding_method == 'FLAN-T5-ENCODER':\n",
    "            return get_embedding_t5_encoder(X, y, model=model, flan=True, prefix=EMBEDDING_PREFIX)\n",
    "        elif embedding_method == 'FLAN-T5-SCORES':\n",
    "            return get_embedding_t5_scores(X, y, model)\n",
    "        elif embedding_method == 'FLAN-T5-SCORES+ENCODER':\n",
    "            return get_embedding_t5_scores(X, y, model, get_encoder=True)\n",
    "        else:\n",
    "            raise Exception(f\"The embedding method `{embedding_method}` is not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3W_fUcyiGjyk",
   "metadata": {
    "id": "3W_fUcyiGjyk"
   },
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ygllI3PXYz3Q",
   "metadata": {
    "id": "ygllI3PXYz3Q"
   },
   "outputs": [],
   "source": [
    "def sample_balanced(X, y, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[0], seed=0):\n",
    "    seen = [False] * len(X) # Flag used for not including already seen samples twice.\n",
    "    sampled_X = []\n",
    "    sampled_y = []\n",
    "    rest_X    = []\n",
    "    rest_y    = []\n",
    "\n",
    "    for class_name in CLASSES:\n",
    "        partial_X = []\n",
    "        partial_y = []\n",
    "        for i, (ax, ay) in enumerate(zip(X, y)):\n",
    "            if seen[i] == False and class_name in ay: # May include 1+ types in MPQA-T task because of using 'in' keyword instead of '=='.\n",
    "                seen[i] = True\n",
    "                partial_X.append(ax)\n",
    "                partial_y.append(ay)\n",
    "\n",
    "        sampled_ids = sample_without_replacement(len(partial_X), number_of_samples, random_state=seed)\n",
    "        for id in range(len(partial_X)):\n",
    "            if id in sampled_ids:\n",
    "                sampled_X.append(partial_X[id])\n",
    "                sampled_y.append(partial_y[id])\n",
    "            else:\n",
    "                rest_X.append(partial_X[id])\n",
    "                rest_y.append(partial_y[id])\n",
    "\n",
    "    return sampled_X, sampled_y, rest_X, rest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88g_UVW8xFsv",
   "metadata": {
    "id": "88g_UVW8xFsv"
   },
   "outputs": [],
   "source": [
    "def sample_random(X, y, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[0], seed=0):\n",
    "    sampled_X = []\n",
    "    sampled_y = []\n",
    "    rest_X    = []\n",
    "    rest_y    = []\n",
    "\n",
    "    sampled_ids = sample_without_replacement(len(X), number_of_samples, random_state=seed)\n",
    "    for id in range(len(X)):\n",
    "        if id in sampled_ids:\n",
    "            sampled_X.append(X[id])\n",
    "            sampled_y.append(y[id])\n",
    "        else:\n",
    "            rest_X.append(X[id])\n",
    "            rest_y.append(y[id])\n",
    "\n",
    "    return sampled_X, sampled_y, rest_X, rest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CXG2jrCEb47N",
   "metadata": {
    "id": "CXG2jrCEb47N"
   },
   "outputs": [],
   "source": [
    "def sample_kmeans_random(X, y, emb, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[0], seed=0):\n",
    "    km = KMeans(n_clusters=number_of_samples, init=KMEANS_INIT, n_init=KMEANS_CENTROID_SEEDS, max_iter=300, random_state=seed, algorithm=KMEANS_ALGORITHM)\n",
    "    km.fit(emb)\n",
    "    centers = np.array(km.cluster_centers_)\n",
    "    cluster_ids, cluster_sizes = np.unique(km.labels_, return_counts=True)\n",
    "    print(f\"Number of elements assigned to each cluster: {cluster_sizes}\")\n",
    "\n",
    "    sampled_X = []\n",
    "    sampled_y = []\n",
    "    rest_X = []\n",
    "    rest_y = []\n",
    "\n",
    "    for cluster_id in cluster_ids:\n",
    "        cluster_emb = emb[km.labels_ == cluster_id]\n",
    "        selected_ids = np.arange(len(emb))[km.labels_ == cluster_id]\n",
    "        sampled_ids = sample_without_replacement(len(cluster_emb), 1, random_state=seed)\n",
    "        sampled_id = sampled_ids[0]\n",
    "        sampled_X.append(X[selected_ids[sampled_id]])\n",
    "        sampled_y.append(y[selected_ids[sampled_id]])\n",
    "        for i, id in enumerate(selected_ids):\n",
    "            if i != sampled_id:\n",
    "                rest_X.append(X[id])\n",
    "                rest_y.append(y[id])\n",
    "\n",
    "    return sampled_X, sampled_y, rest_X, rest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xrLcABxUUOb7",
   "metadata": {
    "id": "xrLcABxUUOb7"
   },
   "outputs": [],
   "source": [
    "def sample_kmeans_representative(X, y, emb, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[0], seed=0):\n",
    "    km = KMeans(n_clusters=number_of_samples, init=KMEANS_INIT, n_init=KMEANS_CENTROID_SEEDS, max_iter=300, random_state=seed, algorithm=KMEANS_ALGORITHM)\n",
    "    km.fit(emb)\n",
    "    centers = np.array(km.cluster_centers_)\n",
    "    cluster_ids, cluster_sizes = np.unique(km.labels_, return_counts=True)\n",
    "    print(f\"Number of elements assigned to each cluster: {cluster_sizes}\")\n",
    "\n",
    "    sampled_X = []\n",
    "    sampled_y = []\n",
    "    rest_X = []\n",
    "    rest_y = []\n",
    "\n",
    "    for cluster_id in cluster_ids:\n",
    "        cluster_emb = emb[km.labels_ == cluster_id]\n",
    "        selected_ids = np.arange(len(emb))[km.labels_ == cluster_id]\n",
    "        closests, distances = pairwise_distances_argmin_min(centers[cluster_id:cluster_id+1], cluster_emb)\n",
    "        closest = closests[0]\n",
    "        sampled_X.append(X[selected_ids[closest]])\n",
    "        sampled_y.append(y[selected_ids[closest]])\n",
    "        for i, id in enumerate(selected_ids):\n",
    "            if i != closest:\n",
    "                rest_X.append(X[id])\n",
    "                rest_y.append(y[id])\n",
    "\n",
    "    return sampled_X, sampled_y, rest_X, rest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ue2cjoZ3QTTs",
   "metadata": {
    "id": "ue2cjoZ3QTTs"
   },
   "outputs": [],
   "source": [
    "def sample_entropy(X, y, emb, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION, seed=0, encoder_emb=None):\n",
    "    entropies = - np.sum(emb * np.log(emb), axis=1)\n",
    "    sorted_ids = np.argsort(entropies)\n",
    "    sampled_ids = sorted_ids[-number_of_samples:]\n",
    "\n",
    "    sampled_encoder_emb = []\n",
    "    sampled_X = []\n",
    "    sampled_y = []\n",
    "    rest_X = []\n",
    "    rest_y = []\n",
    "\n",
    "    for id in range(len(X)):\n",
    "        if id in sampled_ids:\n",
    "            if encoder_emb is not None:\n",
    "                sampled_encoder_emb.append(encoder_emb[id])\n",
    "            sampled_X.append(X[id])\n",
    "            sampled_y.append(y[id])\n",
    "        else:\n",
    "            rest_X.append(X[id])\n",
    "            rest_y.append(y[id])\n",
    "\n",
    "    if encoder_emb is not None:\n",
    "        return sampled_X, sampled_y, rest_X, rest_y, np.array(sampled_encoder_emb)\n",
    "\n",
    "    return sampled_X, sampled_y, rest_X, rest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4spfylXENylR",
   "metadata": {
    "id": "4spfylXENylR"
   },
   "outputs": [],
   "source": [
    "def sample_entropy_then_kmeans_representative(X, y, emb, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[0], seed=0):\n",
    "\n",
    "    if type(emb).__name__ == 'tuple':\n",
    "        kmeans_emb = emb[1] # Encoder\n",
    "        entropy_emb = emb[0] # Scores\n",
    "    else:\n",
    "        kmeans_emb = emb # Scores\n",
    "        entropy_emb = emb # Scores\n",
    "\n",
    "    sampled_X_1, sampled_y_1, rest_X_1, rest_y_1, sampled_encoder_emb = sample_entropy(X, y, entropy_emb, number_of_samples*UNREP_ALPHA, seed, encoder_emb=kmeans_emb)\n",
    "    sampled_X_2, sampled_y_2, rest_X_2, rest_y_2 = sample_kmeans_representative(sampled_X_1, sampled_y_1, sampled_encoder_emb, number_of_samples, seed)\n",
    "\n",
    "    sampled_X = sampled_X_2\n",
    "    sampled_y = sampled_y_2\n",
    "    rest_X = rest_X_1 + rest_X_2\n",
    "    rest_y = rest_y_1 + rest_y_2\n",
    "\n",
    "    return sampled_X, sampled_y, rest_X, rest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qHjNZXzzPgHZ",
   "metadata": {
    "id": "qHjNZXzzPgHZ"
   },
   "outputs": [],
   "source": [
    "def sample_kmeans_representative_then_entropy(X, y, emb, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[0], seed=0):\n",
    "\n",
    "    if type(emb).__name__ == 'tuple':\n",
    "        kmeans_emb = emb[1] # Encoder\n",
    "        entropy_emb = emb[0] # Scores\n",
    "    else:\n",
    "        kmeans_emb = emb # Scores\n",
    "        entropy_emb = emb # Scores\n",
    "\n",
    "    km = KMeans(n_clusters=number_of_samples, init=KMEANS_INIT, n_init=KMEANS_CENTROID_SEEDS, max_iter=300, random_state=seed, algorithm=KMEANS_ALGORITHM)\n",
    "    km.fit(kmeans_emb)\n",
    "    centers = np.array(km.cluster_centers_)\n",
    "    cluster_ids, cluster_sizes = np.unique(km.labels_, return_counts=True)\n",
    "    print(f\"Number of elements assigned to each cluster: {cluster_sizes}\")\n",
    "\n",
    "    sampled_X = []\n",
    "    sampled_y = []\n",
    "    rest_X = []\n",
    "    rest_y = []\n",
    "\n",
    "    for cluster_id in cluster_ids:\n",
    "\n",
    "        cluster_entropy_emb = entropy_emb[km.labels_ == cluster_id]\n",
    "        selected_ids = np.arange(len(entropy_emb))[km.labels_ == cluster_id]\n",
    "        cluster_X = []\n",
    "        cluster_y = []\n",
    "        for id in selected_ids:\n",
    "            cluster_X.append(X[id])\n",
    "            cluster_y.append(y[id])\n",
    "\n",
    "        one_sampled_X, one_sampled_y, rest_cluster_X, rest_cluster_y = sample_entropy(cluster_X, cluster_y, cluster_entropy_emb, 1, seed)\n",
    "\n",
    "        sampled_X += one_sampled_X\n",
    "        sampled_y += one_sampled_y\n",
    "        rest_X += rest_cluster_X\n",
    "        rest_y += rest_cluster_y\n",
    "\n",
    "    return sampled_X, sampled_y, rest_X, rest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4w_K1sG2wdfx",
   "metadata": {
    "id": "4w_K1sG2wdfx"
   },
   "outputs": [],
   "source": [
    "def sample(X, y, emb=None, sampling_method=SAMPLING_METHOD_FIRST_ITERATION, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[0], seed=0):\n",
    "    if sampling_method == 'BALANCED':\n",
    "        return sample_balanced(X, y, number_of_samples, seed)\n",
    "    elif sampling_method == 'RANDOM':\n",
    "        return sample_random(X, y, number_of_samples, seed)\n",
    "    elif sampling_method == 'KMEANS_RANDOM':\n",
    "        return sample_kmeans_random(X, y, emb, number_of_samples, seed)\n",
    "    elif sampling_method == 'KMEANS_REPRESENTATIVE':\n",
    "        return sample_kmeans_representative(X, y, emb, number_of_samples, seed)\n",
    "    elif sampling_method == 'ENTROPY':\n",
    "        return sample_entropy(X, y, emb, number_of_samples, seed)\n",
    "    elif sampling_method == 'ENTROPY_THEN_KMEANS_REPRESENTATIVE':\n",
    "        return sample_entropy_then_kmeans_representative(X, y, emb, number_of_samples, seed)\n",
    "    elif sampling_method == 'KMEANS_REPRESENTATIVE_THEN_ENTROPY':\n",
    "        return sample_kmeans_representative_then_entropy(X, y, emb, number_of_samples, seed)\n",
    "    else:\n",
    "        raise Exception(f\"The sampling method `{sampling_method}` is not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O2FIRYcgGnVK",
   "metadata": {
    "id": "O2FIRYcgGnVK"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ec8jLHChPuH3",
   "metadata": {
    "id": "Ec8jLHChPuH3"
   },
   "outputs": [],
   "source": [
    "%mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n1F5NUhkJ2bf",
   "metadata": {
    "id": "n1F5NUhkJ2bf"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "folds_val_log          = INIT_FOLDS_VAL_LOG\n",
    "folds_test_log         = INIT_FOLDS_TEST_LOG\n",
    "preds_texts_val_list   = INIT_PREDS_TEXTS_VAL_LIST\n",
    "targets_texts_val_list = INIT_TARGETS_TEXTS_VAL_LIST\n",
    "sampled_list           = INIT_SAMPLED_LIST\n",
    "duration_log = ''\n",
    "\n",
    "for fold_counter in range(MAX_FOLDS):\n",
    "    print(f'\\n\\033[1mFold {fold_counter}/{MAX_FOLDS-1}:\\033[0m')\n",
    "\n",
    "    for seed_counter in range(SKIP_SAMPLING_SEEDS, REPEAT_SAMPLING):\n",
    "        print(f'\\n\\033[1mFold {fold_counter}/{MAX_FOLDS-1} | Seed {seed_counter}/{REPEAT_SAMPLING-1}:\\033[0m')\n",
    "\n",
    "        set_seed()\n",
    "\n",
    "        folds_val_log[-1].append([])\n",
    "        folds_test_log[-1].append([])\n",
    "        preds_texts_val_list[-1].append([])\n",
    "        sampled_list[-1].append([])\n",
    "\n",
    "        if seed_counter > 0: # Reset Model\n",
    "            model.cpu()\n",
    "            del model\n",
    "            free_gpu()\n",
    "\n",
    "        model=None\n",
    "        (X_train_rest, y_train_rest), (X_val, y_val), (X_test, y_test) = fetch_dataset(dataset_name=DATASET_NAME, fold=fold_counter, show_counter=(seed_counter==0))\n",
    "        X_train, y_train = [], []\n",
    "\n",
    "        for sampling_iteration in range(SAMPLING_ITERATIONS):\n",
    "            print(f'\\n\\033[1mFold {fold_counter}/{MAX_FOLDS-1} | Seed {seed_counter}/{REPEAT_SAMPLING-1} | Iteration {sampling_iteration}/{SAMPLING_ITERATIONS-1}:\\033[0m')\n",
    "            duration_log += f'Fold {fold_counter}/{MAX_FOLDS-1} | Seed {seed_counter}/{REPEAT_SAMPLING-1} | Iteration {sampling_iteration}/{SAMPLING_ITERATIONS-1}:\\n'\n",
    "\n",
    "            logging.disable(logging.INFO)\n",
    "\n",
    "            embedding_method = EMBEDDING_METHOD_FIRST_ITERATION if sampling_iteration == 0 or EMBEDDING_METHOD_SECOND_ITERATION_PLUS == \"SAME_AS_BEFORE\" else EMBEDDING_METHOD_SECOND_ITERATION_PLUS\n",
    "            sampling_method  = SAMPLING_METHOD_FIRST_ITERATION  if sampling_iteration == 0 or SAMPLING_METHOD_SECOND_ITERATION_PLUS  == \"SAME_AS_BEFORE\" else SAMPLING_METHOD_SECOND_ITERATION_PLUS\n",
    "\n",
    "            embedding_start_time = datetime.now()\n",
    "            if sampling_method in ['RANDOM', 'BALANCED']:\n",
    "                emb_train = None\n",
    "            else:\n",
    "                emb_train = get_embedding(X_train_rest, y_train_rest, embedding_method=embedding_method, model=model)\n",
    "            duration_log += f'Embedding Time: {datetime.now()-embedding_start_time}\\n'\n",
    "\n",
    "            sampling_start_time = datetime.now()\n",
    "            X_train_sampled, y_train_sampled, X_train_rest, y_train_rest = sample(X_train_rest, y_train_rest, emb_train, sampling_method=sampling_method, number_of_samples=NUMBER_OF_SAMPLES_PER_ITERATION[sampling_iteration], seed=seed_counter)\n",
    "            duration_log += f'Sampling Time: {datetime.now()-sampling_start_time}\\n'\n",
    "\n",
    "            if AFL_APPROACH == 'IN-CONTEXT':\n",
    "                X_train_sampled = [x.splitlines()[-1] for x in X_train_sampled]\n",
    "\n",
    "                support_set_context_sampled = ''\n",
    "                for x, y in zip(X_train_sampled, y_train_sampled):\n",
    "                    support_set_context_sampled += x + ' ' + y + '\\n'\n",
    "\n",
    "                X_train_rest = [support_set_context_sampled + x for x in X_train_rest]\n",
    "                X_val        = [support_set_context_sampled + x for x in X_val]\n",
    "                X_test       = [support_set_context_sampled + x for x in X_test]\n",
    "\n",
    "            sampled_list[-1][-1].append((X_train_sampled, y_train_sampled))\n",
    "\n",
    "            X_train += X_train_sampled\n",
    "            y_train += y_train_sampled\n",
    "\n",
    "            Xy_train_tokenized = tokenize_inputs(tokenizer, tuple(X_train), tuple(y_train)) if seed_counter != 0 else tokenize_and_show_inputs(tokenizer, X_train, y_train)\n",
    "            Xy_val_tokenized   = tokenize_inputs(tokenizer, tuple(X_val),   tuple(y_val))\n",
    "            Xy_test_tokenized  = tokenize_inputs(tokenizer, tuple(X_test),  tuple(y_test))\n",
    "\n",
    "            n_train_samples = len(X_train)\n",
    "            n_val_samples   = len(X_val)\n",
    "            n_test_samples  = len(X_test)\n",
    "\n",
    "            n_samples = n_train_samples + n_val_samples + n_test_samples\n",
    "            if seed_counter == 0:\n",
    "                print(f'Train set size:      {n_train_samples} \\t({100*n_train_samples/n_samples}%)')\n",
    "                print(f'Validation set size: {n_val_samples} \\t({100*n_val_samples/n_samples}%)')\n",
    "                print(f'Test set size:       {n_test_samples} \\t({100*n_test_samples/n_samples}%)')\n",
    "                print()\n",
    "\n",
    "            train_dataset = get_dataset(Xy_train_tokenized)\n",
    "            val_dataset   = get_dataset(Xy_val_tokenized)\n",
    "            test_dataset  = get_dataset(Xy_test_tokenized)\n",
    "\n",
    "            if sampling_iteration == 0 or RESET_MODEL_AFTER_EACH_ITERATION: # Reset Model\n",
    "                free_gpu()\n",
    "                model = load_model(MODEL_NAME)\n",
    "                model = model.to(device)\n",
    "\n",
    "            optimizer = load_optimizer(model)\n",
    "            X_eval, y_eval = X_val, y_val\n",
    "            %mkdir models\n",
    "            trainer = setup_trainer(model, train_dataset, val_dataset, optimizer, fold_counter, seed_counter)\n",
    "\n",
    "            if AFL_APPROACH == \"FINE-TUNING\":\n",
    "                ft_start_time = datetime.now()\n",
    "                trainer.train()\n",
    "                duration_log += f'Fine-Tuning Time: {datetime.now()-sampling_start_time}\\n'\n",
    "\n",
    "            X_eval, y_eval = X_val, y_val\n",
    "            val_results  = trainer.evaluate(val_dataset)\n",
    "            X_eval, y_eval = X_test, y_test\n",
    "            test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "            # Best Epochs\n",
    "            if AFL_APPROACH == \"FINE-TUNING\":\n",
    "                if os.path.exists(f'models/{EXPERIMENT_NAME}_{fold_counter}_{seed_counter}'):\n",
    "                    best_epoch = int(os.listdir(f'models/{EXPERIMENT_NAME}_{fold_counter}_{seed_counter}')[0].split('-')[-1]) * PER_DEVICE_TRAIN_BATCH_SIZE / n_train_samples\n",
    "                    val_results['best_epoch'] = best_epoch\n",
    "                    test_results['best_epoch'] = best_epoch\n",
    "            elif AFL_APPROACH == \"IN-CONTEXT\":\n",
    "                val_results['best_epoch'] = 0\n",
    "                test_results['best_epoch'] = 0\n",
    "            %rm -r models\n",
    "\n",
    "            folds_val_log[-1][-1].append(val_results)\n",
    "            folds_test_log[-1][-1].append(test_results)\n",
    "\n",
    "            X_eval, y_eval = X_val, y_val\n",
    "            pred_val = trainer.predict(val_dataset)\n",
    "            preds_tokens_val = pred_val.predictions\n",
    "            preds_texts_val = batch_detokenize(tokenizer, preds_tokens_val)\n",
    "            preds_texts_val_list[-1][-1].append(preds_texts_val)\n",
    "\n",
    "            logging.disable(logging.NOTSET)\n",
    "\n",
    "        print(\"======== CHECKPOINT ========\")\n",
    "\n",
    "        checkpoint = {\n",
    "            'INIT_FOLDS_VAL_LOG': folds_val_log,\n",
    "            'INIT_FOLDS_TEST_LOG': folds_test_log,\n",
    "            'INIT_PREDS_TEXTS_VAL_LIST': preds_texts_val_list,\n",
    "            'INIT_SAMPLED_LIST': sampled_list\n",
    "        }\n",
    "\n",
    "        with open(f'results/{EXPERIMENT_NAME.replace(\".ipynb\", \"\")}_checkpoint.json', 'w', encoding ='utf8') as checkpoint_file:\n",
    "            json.dump(checkpoint, checkpoint_file, ensure_ascii=False, indent=1)\n",
    "\n",
    "    targets_tokens_val = np.array(pred_val.label_ids, dtype=int)\n",
    "    targets_texts_val = batch_detokenize(tokenizer, targets_tokens_val)\n",
    "    targets_texts_val_list.append(targets_texts_val)\n",
    "    print(f\"INIT_TARGETS_TEXTS_VAL_LIST = {targets_texts_val_list},\")\n",
    "\n",
    "    if fold_counter < MAX_FOLDS - 1:\n",
    "        folds_val_log.append([])\n",
    "        folds_test_log.append([])\n",
    "        preds_texts_val_list.append([])\n",
    "        sampled_list.append([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6vXgpwu2J2bf",
   "metadata": {
    "id": "6vXgpwu2J2bf"
   },
   "outputs": [],
   "source": [
    "print(\"folds_val_log  =\", folds_val_log)\n",
    "print(\"folds_test_log =\", folds_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vxQIgYrmgjIT",
   "metadata": {
    "id": "vxQIgYrmgjIT"
   },
   "outputs": [],
   "source": [
    "with open(f'results/{EXPERIMENT_NAME.replace(\".ipynb\", \"\")}_duration.log', 'w') as f:\n",
    "    f.write(duration_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oi5swcph39OC",
   "metadata": {
    "id": "oi5swcph39OC"
   },
   "outputs": [],
   "source": [
    "dataset = get_dataset(Xy_train_tokenized)\n",
    "dataloader = get_dataloader(dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fQg6_JBI5CZg",
   "metadata": {
    "id": "fQg6_JBI5CZg"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    scores = None # (len(X), NUM_CLASSES)\n",
    "    for batch in dataloader:\n",
    "        gpu_batch = {k:v.to(device) for k,v in batch.items() if k != 'labels'}\n",
    "        output = model.generate(**gpu_batch, return_dict_in_generate=True, output_scores=True, max_new_tokens=MAX_NEW_TOKENS, renormalize_logits=True) # output.sequences: (batch_size, seq_len+1!) | output.scores: (seq_len, batch_size, vocab_size)!\n",
    "        print(torch.min(output.scores[0]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CVGgVFaFY4sN",
   "metadata": {
    "id": "CVGgVFaFY4sN"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j5lk3DzPJ2bf",
   "metadata": {
    "id": "j5lk3DzPJ2bf"
   },
   "outputs": [],
   "source": [
    "def print_log(folds_log, portion):\n",
    "    if portion == 'Train':\n",
    "        color = '\\033[1;31m'\n",
    "    elif portion == 'Validation':\n",
    "        color = '\\033[1;32m'\n",
    "    elif portion == 'Test':\n",
    "        color = '\\033[1;36m'\n",
    "\n",
    "    ignored_metrics = ['eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch', 'best_epoch']\n",
    "    highlighted_metrics = ['eval_bleu_score', 'eval_type_micro_f1', 'eval_polarity_accuracy', 'eval_intensity_accuracy', 'eval_average_of_metrics']\n",
    "\n",
    "    print(f'{color}{portion}:\\033[0m')\n",
    "    print(f'\\033[1mBased on steps with best {METRIC_FOR_BEST_MODEL}\\033[0m')\n",
    "\n",
    "    for metric_name in folds_log[0][0][-1].keys():\n",
    "        if metric_name in ignored_metrics:\n",
    "            continue\n",
    "        metric_values_in_each_fold = []\n",
    "        for fold_log in folds_log:\n",
    "            metric_values_in_each_fold.append(np.round([seed_log[-1][metric_name] for seed_log in fold_log], 6).tolist())\n",
    "        average_metric_values_in_each_fold = np.round(np.mean(metric_values_in_each_fold, axis=1), 6)\n",
    "        average = np.round(np.mean(average_metric_values_in_each_fold, axis=0), 6)\n",
    "        print()\n",
    "        if metric_name in highlighted_metrics:\n",
    "            print(f'\\033[1m{metric_name}:\\033[0m {metric_values_in_each_fold}')\n",
    "            print(f'\\033[1meach fold:\\033[0m {average_metric_values_in_each_fold}\\033[0m')\n",
    "            print(f'\\033[1maverage:  \\033[0m {color}{average}\\033[0m')\n",
    "        else:\n",
    "            print(f'\\033[1m{metric_name}:\\033[0m {metric_values_in_each_fold}')\n",
    "            print(f'\\033[1meach fold:\\033[0m {average_metric_values_in_each_fold}\\033[0m')\n",
    "            print(f'\\033[1maverage:\\033[0m {average}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unugBZ_1aVqe",
   "metadata": {
    "id": "unugBZ_1aVqe"
   },
   "outputs": [],
   "source": [
    "# print_log(folds_train_log, 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LLbvbz9pgajZ",
   "metadata": {
    "id": "LLbvbz9pgajZ"
   },
   "outputs": [],
   "source": [
    "print_log(folds_val_log, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ElfTO1c3Enmi",
   "metadata": {
    "id": "ElfTO1c3Enmi"
   },
   "outputs": [],
   "source": [
    "print_log(folds_test_log, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sQWxkAhRcIVM",
   "metadata": {
    "id": "sQWxkAhRcIVM"
   },
   "outputs": [],
   "source": [
    "print('\\033[1m Early Stopping: \\033[0m', end = '')\n",
    "print(f'{np.round(EARLY_STOPPING, 2)} \\n', end='')\n",
    "\n",
    "print('\\033[1m Epochs: \\033[0m', end = '')\n",
    "epochs_in_each_fold = []\n",
    "for fold_log in folds_val_log:\n",
    "    epochs_in_each_fold.append(np.round([seed_log[-1]['epoch'] for seed_log in fold_log], 2).tolist())\n",
    "average_epochs_in_each_fold = np.round(np.mean(epochs_in_each_fold, axis=0), 2)\n",
    "average = np.round(np.mean(average_epochs_in_each_fold, axis=0), 2)\n",
    "print(f'{average} ', end='')\n",
    "print(f'  \\t\\t\\t\\t\\t\\t raw: {epochs_in_each_fold}')\n",
    "\n",
    "print('\\033[1m Epoch in Which the Best Results Were Achieved: \\033[0m', end = '')\n",
    "best_epoch_in_each_fold = []\n",
    "for fold_log in folds_val_log:\n",
    "    best_epoch_in_each_fold.append(np.round([seed_log[-1]['best_epoch'] for seed_log in fold_log], 2).tolist())\n",
    "average_best_epoch_in_each_fold = np.round(np.mean(best_epoch_in_each_fold, axis=0), 2)\n",
    "average = np.round(np.mean(average_best_epoch_in_each_fold, axis=0), 2)\n",
    "print(f'{average} ', end='')\n",
    "print(f'  \\t raw: {best_epoch_in_each_fold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oumTpyqnJ2bh",
   "metadata": {
    "id": "oumTpyqnJ2bh"
   },
   "source": [
    "# Save/Load model to/from Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_hsHv41JJ2bh",
   "metadata": {
    "id": "_hsHv41JJ2bh"
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vOR57XOeJ2bh",
   "metadata": {
    "id": "vOR57XOeJ2bh"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2yjGlByVJ2bh",
   "metadata": {
    "id": "2yjGlByVJ2bh"
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L5Csa58uJ2bi",
   "metadata": {
    "id": "L5Csa58uJ2bi"
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7CJhx9-TJ2bh",
   "metadata": {
    "id": "7CJhx9-TJ2bh"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lPwuRJNEJ2bh",
   "metadata": {
    "id": "lPwuRJNEJ2bh"
   },
   "outputs": [],
   "source": [
    "# model_save_name = 'a_great_name'\n",
    "\n",
    "# path = f'/content/gdrive/MyDrive/MPQA/models/{model_save_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oOzPfkUAJ2bi",
   "metadata": {
    "id": "oOzPfkUAJ2bi"
   },
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-w-LzOX8UqeF",
   "metadata": {
    "id": "-w-LzOX8UqeF"
   },
   "outputs": [],
   "source": [
    "%mkdir results/preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pYTVRnJv2K5I",
   "metadata": {
    "id": "pYTVRnJv2K5I"
   },
   "outputs": [],
   "source": [
    "# Extract X_val_type from input\n",
    "\n",
    "X_val_type = None\n",
    "if DATASET_NAME in ['MPQA-P', 'MPQA-I']:\n",
    "    X_val_type = [x.split(' | ')[0] for x in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QyqPeQnvJ2bi",
   "metadata": {
    "id": "QyqPeQnvJ2bi"
   },
   "outputs": [],
   "source": [
    "if SHOW_VAL_PREDICTIONS == True:\n",
    "\n",
    "    candidates_val = preds_texts_val_list[0][0][-1]\n",
    "    referenceses_val = merge_samples(X_val, targets_texts_val_list[0])\n",
    "    squeezed_X, squeezed_candidates, squeezed_referenceses = squeeze_samples(X_val, candidates_val, referenceses_val)\n",
    "\n",
    "    with open(f'results/preds/{EXPERIMENT_NAME}_val_predictions.txt', 'w') as f:\n",
    "        if RUNTIME_TYPE == 'CONDA':\n",
    "            original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "            sys.stdout = f # Change the standard output to the file we created.\n",
    "\n",
    "        CNT = 0\n",
    "        for i in range(len(squeezed_X)):\n",
    "            # if candidates[i] not in referenceses[i]:\n",
    "            CNT += 1\n",
    "            print(f'\\n#{CNT}')\n",
    "            print(f'┌X: {repr(squeezed_X[i])}')\n",
    "            print(f'├C: {repr(squeezed_candidates[i])}')\n",
    "            print(f'└R: {squeezed_referenceses[i]}')\n",
    "\n",
    "        if RUNTIME_TYPE == 'CONDA':\n",
    "            sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i2DVUCf0RtT9",
   "metadata": {
    "id": "i2DVUCf0RtT9"
   },
   "outputs": [],
   "source": [
    "# Store raw outputs\n",
    "\n",
    "with open(f'results/preds/{EXPERIMENT_NAME}_raw_val_predictions.txt', 'w') as f:\n",
    "    original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "    sys.stdout = f # Change the standard output to the file we created.\n",
    "\n",
    "    print('X_val =', X_val)\n",
    "    print('preds_texts_val_list =', preds_texts_val_list)\n",
    "    print('targets_texts_val_list =', targets_texts_val_list)\n",
    "\n",
    "    sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qw5F0H6MYZAS",
   "metadata": {
    "id": "qw5F0H6MYZAS"
   },
   "outputs": [],
   "source": [
    "# Store sampled Data\n",
    "\n",
    "with open(f'results/preds/{EXPERIMENT_NAME}_sampled_data.txt', 'w') as f:\n",
    "    original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "    sys.stdout = f # Change the standard output to the file we created.\n",
    "\n",
    "    for fold_counter in range(MAX_FOLDS):\n",
    "        print(f'█████ FOLD: {fold_counter}/{MAX_FOLDS-1} ████████████████████████████████████████████████████████████████')\n",
    "        for seed_counter in range(REPEAT_SAMPLING):\n",
    "            print(f'════╡ {fold_counter} ╞═╡ SEED: {seed_counter}/{REPEAT_SAMPLING-1} ╞═════════════════════════════════════════════════════════')\n",
    "            for sampling_iteration in range(SAMPLING_ITERATIONS):\n",
    "                print(f'────┤ {fold_counter} ├─┤ {seed_counter} ├─┤ ITER: {sampling_iteration}/{SAMPLING_ITERATIONS-1} ├───────────────────────────────────────────────────')\n",
    "                Xs, ys = sampled_list[fold_counter][seed_counter][sampling_iteration]\n",
    "                for ax, ay in zip(Xs, ys):\n",
    "                    print(f'┌X: {repr(ax)}')\n",
    "                    print(f'└y: {repr(ay)}')\n",
    "\n",
    "    sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NbYC9Q4RUZp_",
   "metadata": {
    "id": "NbYC9Q4RUZp_"
   },
   "outputs": [],
   "source": [
    "if DATASET_NAME == 'MPQA-T':\n",
    "    targets_vecs = outputs_text_to_vec(targets_texts_val_list[0])\n",
    "    preds_vecs   = outputs_text_to_vec(preds_texts_val_list[0][0][-1])\n",
    "\n",
    "    count_targets = np.sum(np.sum(targets_vecs[:, :NUM_TYPE_CLASSES], axis=1) > 1)\n",
    "    count_preds   = np.sum(np.sum(preds_vecs[:, :NUM_TYPE_CLASSES], axis=1) > 1)\n",
    "\n",
    "    print(f' Actual multi-type samples:    {count_targets}\\n Predicted multi-type samples: {count_preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vBjtB62K02Mj",
   "metadata": {
    "id": "vBjtB62K02Mj"
   },
   "outputs": [],
   "source": [
    "if DATASET_NAME == 'MPQA-I':\n",
    "    preds_vecs = outputs_text_to_vec(preds_texts_val_list[0][0][-1])\n",
    "    for i in range(len(preds_vecs)):\n",
    "        if (preds_vecs[i] == [1, 0, 1]).all():\n",
    "            print(i, preds_vecs[i])\n",
    "        if (preds_vecs[i] == [1, 0, 1]).all():\n",
    "            print(i, preds_vecs[i])\n",
    "        if (preds_vecs[i] == [0, 0, 0]).all():\n",
    "            print(i, preds_vecs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pK5AmBQa4sg8",
   "metadata": {
    "id": "pK5AmBQa4sg8"
   },
   "source": [
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B7_EGzBemWws",
   "metadata": {
    "id": "B7_EGzBemWws"
   },
   "outputs": [],
   "source": [
    "def clean_the_metric_name(name):\n",
    "    return name.\\\n",
    "        replace(\"eval_\", \"\").\\\n",
    "        replace(\"_\", \" \").\\\n",
    "        replace(\"type\", \"T\").\\\n",
    "        replace(\"polarity\", \"P\").\\\n",
    "        replace(\"intensity\", \"I\").\\\n",
    "        replace(\"accuracy\", \"ACC\").\\\n",
    "        replace(\"exact match ratio\", \"EMR\").\\\n",
    "        replace(\"f1\", \"F1\").\\\n",
    "        replace(\"micro \", \"\").\\\n",
    "        replace(\"weighted\", \"\").\\\n",
    "        replace(\"average of metrics\", \"AVG\")\n",
    "\n",
    "if STORE_RESULTS != []:\n",
    "    if not os.path.exists('results.csv'):\n",
    "        with open(f'results.csv', 'w') as f:\n",
    "            original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "            sys.stdout = f # Change the standard output to the file we created.\n",
    "\n",
    "            print('Experiment Name, ', end='')\n",
    "            print('Iter, ', end='')\n",
    "            print('║, ', end='')\n",
    "\n",
    "            for split in ['val', 'tst']:\n",
    "                first_metric = True\n",
    "                for metric_name in STORE_RESULTS:\n",
    "                    if first_metric:\n",
    "                        first_metric = False\n",
    "                    else:\n",
    "                        print('│, ', end='')\n",
    "                    print(f'{split} {clean_the_metric_name(metric_name)}, ', end='')\n",
    "                    for fold_counter in range(MAX_FOLDS):\n",
    "                        if MAX_FOLDS > 1:\n",
    "                            print('|, ', end='')\n",
    "                            print(f'fold{fold_counter+1}, ', end='')\n",
    "                        if REPEAT_SAMPLING > 1:\n",
    "                            print('|, ', end='')\n",
    "                            for seed_counter in range(REPEAT_SAMPLING):\n",
    "                                print(f'seed{seed_counter}, ', end='')\n",
    "                print('║, ', end='')\n",
    "\n",
    "            print(f'earlystopping, ', end='')\n",
    "            print(f'epochs, ', end='')\n",
    "            print(f'best epoch ', end = '')\n",
    "            print()\n",
    "\n",
    "            sys.stdout = original_stdout # Reset the standard output to its original value\n",
    "\n",
    "    with open(f'results.csv', 'a') as f:\n",
    "        original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "        sys.stdout = f # Change the standard output to the file we created.\n",
    "\n",
    "        for sampling_iteration in range(SAMPLING_ITERATIONS):\n",
    "            print(f'{EXPERIMENT_NAME.replace(\".ipynb\", \"\").replace(\"_\", \" \").replace(\",\", \".\")}, ', end='')\n",
    "            print(f'{sampling_iteration}, ', end='')\n",
    "            print(f'║, ', end='')\n",
    "\n",
    "            for split in [folds_val_log, folds_test_log]:\n",
    "                first_metric = True\n",
    "                for metric_name in STORE_RESULTS:\n",
    "                    if first_metric:\n",
    "                        first_metric = False\n",
    "                    else:\n",
    "                        print('│, ', end='')\n",
    "                    if metric_name in folds_val_log[0][0][sampling_iteration]:\n",
    "                        metric_values = np.array([[split[fold_counter][seed_counter][sampling_iteration][metric_name] for seed_counter in range(REPEAT_SAMPLING)] for fold_counter in range(MAX_FOLDS)])\n",
    "                        print(f'{np.round(np.mean(metric_values), 6)}, ', end='')\n",
    "                        for fold_counter in range(MAX_FOLDS):\n",
    "                            if MAX_FOLDS > 1:\n",
    "                                print('|, ', end='')\n",
    "                                print(f'{np.round(np.mean(metric_values[fold_counter]), 6)}, ', end='')\n",
    "                            if REPEAT_SAMPLING > 1:\n",
    "                                print('|, ', end='')\n",
    "                                for seed_counter in range(REPEAT_SAMPLING):\n",
    "                                    print(f'{np.round(metric_values[fold_counter][seed_counter], 6)}, ', end='')\n",
    "                    else:\n",
    "                        for i in range(MAX_FOLDS*REPEAT_SAMPLING + MAX_FOLDS + 1):\n",
    "                            print('-, ', end='')\n",
    "                            for fold_counter in range(MAX_FOLDS):\n",
    "                                if MAX_FOLDS > 1:\n",
    "                                    print('|, ', end='')\n",
    "                                    print('-, ', end='')\n",
    "                                if REPEAT_SAMPLING > 1:\n",
    "                                    print('|, ', end='')\n",
    "                                    for seed_counter in range(REPEAT_SAMPLING):\n",
    "                                        print('-, ', end='')\n",
    "                print('║, ', end='')\n",
    "\n",
    "            print(f'{np.round(EARLY_STOPPING, 2)}, ', end='')\n",
    "\n",
    "            epochs = [folds_val_log[fold_counter][seed_counter][sampling_iteration]['epoch'] for fold_counter, seed_counter in itertools.product(range(MAX_FOLDS), range(REPEAT_SAMPLING))]\n",
    "            average = np.round(np.mean(epochs, axis=0), 2)\n",
    "            print(f'{average}, ', end='')\n",
    "\n",
    "            best_epochs = [folds_val_log[fold_counter][seed_counter][sampling_iteration]['best_epoch'] for fold_counter, seed_counter in itertools.product(range(MAX_FOLDS), range(REPEAT_SAMPLING))]\n",
    "            average = np.round(np.mean(best_epochs, axis=0), 2)\n",
    "            print(f'{average} ', end='')\n",
    "\n",
    "            print()\n",
    "\n",
    "        sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7jnbajtw4oL8",
   "metadata": {
    "id": "7jnbajtw4oL8"
   },
   "outputs": [],
   "source": [
    "print_log(folds_test_log, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VUPs8IH-4j5V",
   "metadata": {
    "id": "VUPs8IH-4j5V"
   },
   "outputs": [],
   "source": [
    "print_log(folds_val_log, 'Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oaHBIW8bf2F7",
   "metadata": {
    "id": "oaHBIW8bf2F7"
   },
   "source": [
    "# Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zznzDHU3Z8qO",
   "metadata": {
    "id": "zznzDHU3Z8qO"
   },
   "outputs": [],
   "source": [
    "# Time data\n",
    "\n",
    "end_time = datetime.now() # end timer\n",
    "\n",
    "print('\\033[1mStart:\\033[0m {}'.format(start_time))\n",
    "print('\\033[1mEnd:\\033[0m {}'.format(end_time))\n",
    "print('\\n\\033[1mDuration:\\033[0m {}'.format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1ddezX21e1w21PneWCY75i87rWOVgG-gl",
     "timestamp": 1712525609361
    },
    {
     "file_id": "1BI8Chbeio294gsnkYCP8P3mwvsdmZ9BH",
     "timestamp": 1711999606799
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
